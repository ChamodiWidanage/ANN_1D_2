{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf",
    "ExecuteTime": {
     "end_time": "2023-12-26T15:14:36.921352200Z",
     "start_time": "2023-12-26T15:14:16.074664700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM",
    "ExecuteTime": {
     "end_time": "2023-12-26T15:14:41.358845300Z",
     "start_time": "2023-12-26T15:14:39.949654900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588 entries, 0 to 587\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Explosive type     588 non-null    object \n",
      " 1   Explosive mass     588 non-null    float64\n",
      " 2   Standoff distance  588 non-null    float64\n",
      " 3   Impulse            588 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 18.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('IDataset2.xlsx')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T15:14:42.890244900Z",
     "start_time": "2023-12-26T15:14:42.827354200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588 entries, 0 to 587\n",
      "Data columns (total 5 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Explosive mass                588 non-null    float64\n",
      " 1   Standoff distance             588 non-null    float64\n",
      " 2   Impulse                       588 non-null    float64\n",
      " 3   Explosive type_Composition B  588 non-null    uint8  \n",
      " 4   Explosive type_TNT            588 non-null    uint8  \n",
      "dtypes: float64(3), uint8(2)\n",
      "memory usage: 15.1 KB\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variable into dummy variables\n",
    "dataset = pd.get_dummies(dataset, columns=['Explosive type'])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T15:14:44.827373800Z",
     "start_time": "2023-12-26T15:14:44.748791400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Explosive mass  Standoff distance    Impulse  Explosive type_Composition B  \\\n0             0.5                1.0  77.067900                             0   \n1             0.5                1.5  58.168617                             0   \n2             0.5                2.5  38.798874                             0   \n3             0.5                3.5  28.473915                             0   \n4             0.5                4.5  22.343452                             0   \n\n   Explosive type_TNT  \n0                   1  \n1                   1  \n2                   1  \n3                   1  \n4                   1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Explosive mass</th>\n      <th>Standoff distance</th>\n      <th>Impulse</th>\n      <th>Explosive type_Composition B</th>\n      <th>Explosive type_TNT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>77.067900</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>1.5</td>\n      <td>58.168617</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>2.5</td>\n      <td>38.798874</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>3.5</td>\n      <td>28.473915</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>4.5</td>\n      <td>22.343452</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T15:14:46.213700100Z",
     "start_time": "2023-12-26T15:14:46.202508600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588, 4) (588,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset[('Impulse')]\n",
    "X = dataset.drop('Impulse', axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T15:14:47.515256Z",
     "start_time": "2023-12-26T15:14:47.439314300Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx",
    "ExecuteTime": {
     "end_time": "2023-12-26T15:14:49.447406200Z",
     "start_time": "2023-12-26T15:14:49.390013200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test,\n",
    "                                                y_test,\n",
    "                                                test_size = 0.5,\n",
    "                                                random_state = 71)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:14:50.634863800Z",
     "start_time": "2023-12-26T15:14:50.608817200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:,0:2] = sc.fit_transform(X_train[:, 0:2])\n",
    "print (X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test[:,0:2] = sc.transform(X_test[:, 0:2])\n",
    "print (X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_val[:,0:2] = sc.transform(X_val[:, 0:2])\n",
    "print (X_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1 - Hyperparameter tuning - layers, neurons, activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T15:21:39.175362800Z",
     "start_time": "2023-12-26T15:21:39.148099700Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n",
    "\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(71)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "def FindLayerNodesLinear( last_layer_nodes):\n",
    "    layers = []\n",
    "    nodes_increment = (last_layer_nodes - 20)/ 2\n",
    "    nodes = 20\n",
    "    for i in range(1, 4):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T15:21:40.909448600Z",
     "start_time": "2023-12-26T15:21:40.885835700Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model1(last_layer_nodes, activation_func):\n",
    "    model = Sequential()\n",
    "    n_nodes = FindLayerNodesLinear(last_layer_nodes)\n",
    "    for i in range(1, 4):\n",
    "        if i==1:\n",
    "            model.add(Dense(units = 20,  input_shape=(X_train.shape[1],), activation=activation_func))\n",
    "            model.add(Dropout(0.1))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            model.add(Dropout(0.1))\n",
    "            \n",
    "    #Finally, the output layer should have a single node in binary classification\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer1 = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer = optimizer1, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "activation_func = ['relu', 'leaky_relu', 'softplus']\n",
    "last_layer_nodes = [10, 20, 30, 40, 50,60, 70, 80,90,100,110,120,130, 140, 150,160, 170, 180, 190, 200]\n",
    "\n",
    "param_grid = dict(model__activation_func = activation_func,model__last_layer_nodes = last_layer_nodes)\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model1 = KerasRegressor(model=create_model1, verbose=0, epochs = 100, batch_size = 50, random_state = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T15:23:22.653363400Z",
     "start_time": "2023-12-26T15:21:44.115503300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.971237 using {'model__activation_func': 'relu', 'model__last_layer_nodes': 200}\n",
      "0.956167 (0.013286) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 10}\n",
      "0.960763 (0.008021) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 20}\n",
      "0.964636 (0.005536) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 30}\n",
      "0.966952 (0.007781) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 40}\n",
      "0.963682 (0.010396) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 50}\n",
      "0.967761 (0.007490) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 60}\n",
      "0.964836 (0.010330) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 70}\n",
      "0.964245 (0.010193) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 80}\n",
      "0.964672 (0.013967) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 90}\n",
      "0.961957 (0.021670) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 100}\n",
      "0.965964 (0.017386) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 110}\n",
      "0.970231 (0.011094) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 120}\n",
      "0.965346 (0.007764) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 130}\n",
      "0.967560 (0.009414) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 140}\n",
      "0.970262 (0.007907) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 150}\n",
      "0.968174 (0.010165) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 160}\n",
      "0.968235 (0.011041) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 170}\n",
      "0.969528 (0.009946) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 180}\n",
      "0.970802 (0.010584) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 190}\n",
      "0.971237 (0.008658) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 200}\n",
      "0.940889 (0.011995) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 10}\n",
      "0.941393 (0.013037) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 20}\n",
      "0.940661 (0.014651) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 30}\n",
      "0.944665 (0.007575) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 40}\n",
      "0.952554 (0.009480) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 50}\n",
      "0.944217 (0.012099) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 60}\n",
      "0.952885 (0.009420) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 70}\n",
      "0.960563 (0.013664) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 80}\n",
      "0.944027 (0.030807) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 90}\n",
      "0.954525 (0.011054) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 100}\n",
      "0.961476 (0.008434) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 110}\n",
      "0.959157 (0.003839) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 120}\n",
      "0.960995 (0.006372) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 130}\n",
      "0.962102 (0.006940) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 140}\n",
      "0.958477 (0.010259) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 150}\n",
      "0.959794 (0.005420) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 160}\n",
      "0.963108 (0.009075) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 170}\n",
      "0.960520 (0.007076) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 180}\n",
      "0.960655 (0.011776) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 190}\n",
      "0.964303 (0.009478) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 200}\n",
      "0.961739 (0.006981) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 10}\n",
      "0.961261 (0.005140) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 20}\n",
      "0.959307 (0.008758) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 30}\n",
      "0.961710 (0.006284) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 40}\n",
      "0.960760 (0.013135) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 50}\n",
      "0.964517 (0.008522) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 60}\n",
      "0.962136 (0.009781) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 70}\n",
      "0.964070 (0.011321) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 80}\n",
      "0.942820 (0.048617) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 90}\n",
      "0.958391 (0.016766) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 100}\n",
      "0.960381 (0.016309) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 110}\n",
      "0.958988 (0.018059) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 120}\n",
      "0.960687 (0.016415) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 130}\n",
      "0.963003 (0.012506) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 140}\n",
      "0.957842 (0.020953) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 150}\n",
      "0.952868 (0.028294) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 160}\n",
      "0.956068 (0.026628) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 170}\n",
      "0.961536 (0.018446) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 180}\n",
      "0.961961 (0.017635) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 190}\n",
      "0.958440 (0.026744) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 200}\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=71)\n",
    "grid1 = GridSearchCV(estimator = model1, param_grid= param_grid, n_jobs=-1, scoring = 'r2', cv=kf)\n",
    "grid_result1 = grid1.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   model__activation_func  model__last_layer_nodes  model__first_layer_nodes  \\\n0                    relu                       10                        10   \n1                    relu                       20                        10   \n2                    relu                       30                        10   \n3                    relu                       40                        10   \n4                    relu                       50                        10   \n5                    relu                       60                        10   \n6                    relu                       70                        10   \n7                    relu                       80                        10   \n8                    relu                       90                        10   \n9                    relu                      100                        10   \n10                   relu                      110                        10   \n11                   relu                      120                        10   \n12                   relu                      130                        10   \n13                   relu                      140                        10   \n14                   relu                      150                        10   \n15                   relu                      160                        10   \n16                   relu                      170                        10   \n17                   relu                      180                        10   \n18                   relu                      190                        10   \n19                   relu                      200                        10   \n20             leaky_relu                       10                        10   \n21             leaky_relu                       20                        10   \n22             leaky_relu                       30                        10   \n23             leaky_relu                       40                        10   \n24             leaky_relu                       50                        10   \n25             leaky_relu                       60                        10   \n26             leaky_relu                       70                        10   \n27             leaky_relu                       80                        10   \n28             leaky_relu                       90                        10   \n29             leaky_relu                      100                        10   \n30             leaky_relu                      110                        10   \n31             leaky_relu                      120                        10   \n32             leaky_relu                      130                        10   \n33             leaky_relu                      140                        10   \n34             leaky_relu                      150                        10   \n35             leaky_relu                      160                        10   \n36             leaky_relu                      170                        10   \n37             leaky_relu                      180                        10   \n38             leaky_relu                      190                        10   \n39             leaky_relu                      200                        10   \n40               softplus                       10                        10   \n41               softplus                       20                        10   \n42               softplus                       30                        10   \n43               softplus                       40                        10   \n44               softplus                       50                        10   \n45               softplus                       60                        10   \n46               softplus                       70                        10   \n47               softplus                       80                        10   \n48               softplus                       90                        10   \n49               softplus                      100                        10   \n50               softplus                      110                        10   \n51               softplus                      120                        10   \n52               softplus                      130                        10   \n53               softplus                      140                        10   \n54               softplus                      150                        10   \n55               softplus                      160                        10   \n56               softplus                      170                        10   \n57               softplus                      180                        10   \n58               softplus                      190                        10   \n59               softplus                      200                        10   \n\n          R2  \n0   0.957277  \n1   0.952770  \n2   0.955750  \n3   0.962781  \n4   0.963277  \n5   0.961489  \n6   0.961639  \n7   0.961165  \n8   0.967092  \n9   0.957607  \n10  0.967332  \n11  0.969310  \n12  0.969345  \n13  0.971354  \n14  0.963988  \n15  0.966790  \n16  0.969455  \n17  0.973595  \n18  0.970083  \n19  0.972797  \n20  0.938008  \n21  0.938011  \n22  0.941324  \n23  0.944782  \n24  0.958124  \n25  0.952277  \n26  0.949166  \n27  0.963180  \n28  0.966446  \n29  0.959306  \n30  0.964877  \n31  0.964370  \n32  0.965344  \n33  0.968206  \n34  0.971026  \n35  0.969427  \n36  0.969014  \n37  0.972984  \n38  0.975211  \n39  0.970634  \n40  0.955033  \n41  0.954675  \n42  0.953263  \n43  0.947949  \n44  0.960033  \n45  0.958685  \n46  0.954219  \n47  0.955721  \n48  0.959191  \n49  0.960752  \n50  0.962199  \n51  0.961534  \n52  0.963043  \n53  0.962995  \n54  0.958927  \n55  0.957555  \n56  0.961822  \n57  0.960407  \n58  0.962330  \n59  0.958215  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model__activation_func</th>\n      <th>model__last_layer_nodes</th>\n      <th>model__first_layer_nodes</th>\n      <th>R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>relu</td>\n      <td>10</td>\n      <td>10</td>\n      <td>0.957277</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>relu</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0.952770</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>relu</td>\n      <td>30</td>\n      <td>10</td>\n      <td>0.955750</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>relu</td>\n      <td>40</td>\n      <td>10</td>\n      <td>0.962781</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>relu</td>\n      <td>50</td>\n      <td>10</td>\n      <td>0.963277</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>relu</td>\n      <td>60</td>\n      <td>10</td>\n      <td>0.961489</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>relu</td>\n      <td>70</td>\n      <td>10</td>\n      <td>0.961639</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>relu</td>\n      <td>80</td>\n      <td>10</td>\n      <td>0.961165</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>relu</td>\n      <td>90</td>\n      <td>10</td>\n      <td>0.967092</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>relu</td>\n      <td>100</td>\n      <td>10</td>\n      <td>0.957607</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>relu</td>\n      <td>110</td>\n      <td>10</td>\n      <td>0.967332</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>relu</td>\n      <td>120</td>\n      <td>10</td>\n      <td>0.969310</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>relu</td>\n      <td>130</td>\n      <td>10</td>\n      <td>0.969345</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>relu</td>\n      <td>140</td>\n      <td>10</td>\n      <td>0.971354</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>relu</td>\n      <td>150</td>\n      <td>10</td>\n      <td>0.963988</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>relu</td>\n      <td>160</td>\n      <td>10</td>\n      <td>0.966790</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>relu</td>\n      <td>170</td>\n      <td>10</td>\n      <td>0.969455</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>relu</td>\n      <td>180</td>\n      <td>10</td>\n      <td>0.973595</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>relu</td>\n      <td>190</td>\n      <td>10</td>\n      <td>0.970083</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>relu</td>\n      <td>200</td>\n      <td>10</td>\n      <td>0.972797</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>leaky_relu</td>\n      <td>10</td>\n      <td>10</td>\n      <td>0.938008</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>leaky_relu</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0.938011</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>leaky_relu</td>\n      <td>30</td>\n      <td>10</td>\n      <td>0.941324</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>leaky_relu</td>\n      <td>40</td>\n      <td>10</td>\n      <td>0.944782</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>leaky_relu</td>\n      <td>50</td>\n      <td>10</td>\n      <td>0.958124</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>leaky_relu</td>\n      <td>60</td>\n      <td>10</td>\n      <td>0.952277</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>leaky_relu</td>\n      <td>70</td>\n      <td>10</td>\n      <td>0.949166</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>leaky_relu</td>\n      <td>80</td>\n      <td>10</td>\n      <td>0.963180</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>leaky_relu</td>\n      <td>90</td>\n      <td>10</td>\n      <td>0.966446</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>leaky_relu</td>\n      <td>100</td>\n      <td>10</td>\n      <td>0.959306</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>leaky_relu</td>\n      <td>110</td>\n      <td>10</td>\n      <td>0.964877</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>leaky_relu</td>\n      <td>120</td>\n      <td>10</td>\n      <td>0.964370</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>leaky_relu</td>\n      <td>130</td>\n      <td>10</td>\n      <td>0.965344</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>leaky_relu</td>\n      <td>140</td>\n      <td>10</td>\n      <td>0.968206</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>leaky_relu</td>\n      <td>150</td>\n      <td>10</td>\n      <td>0.971026</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>leaky_relu</td>\n      <td>160</td>\n      <td>10</td>\n      <td>0.969427</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>leaky_relu</td>\n      <td>170</td>\n      <td>10</td>\n      <td>0.969014</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>leaky_relu</td>\n      <td>180</td>\n      <td>10</td>\n      <td>0.972984</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>leaky_relu</td>\n      <td>190</td>\n      <td>10</td>\n      <td>0.975211</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>leaky_relu</td>\n      <td>200</td>\n      <td>10</td>\n      <td>0.970634</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>softplus</td>\n      <td>10</td>\n      <td>10</td>\n      <td>0.955033</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>softplus</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0.954675</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>softplus</td>\n      <td>30</td>\n      <td>10</td>\n      <td>0.953263</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>softplus</td>\n      <td>40</td>\n      <td>10</td>\n      <td>0.947949</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>softplus</td>\n      <td>50</td>\n      <td>10</td>\n      <td>0.960033</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>softplus</td>\n      <td>60</td>\n      <td>10</td>\n      <td>0.958685</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>softplus</td>\n      <td>70</td>\n      <td>10</td>\n      <td>0.954219</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>softplus</td>\n      <td>80</td>\n      <td>10</td>\n      <td>0.955721</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>softplus</td>\n      <td>90</td>\n      <td>10</td>\n      <td>0.959191</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>softplus</td>\n      <td>100</td>\n      <td>10</td>\n      <td>0.960752</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>softplus</td>\n      <td>110</td>\n      <td>10</td>\n      <td>0.962199</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>softplus</td>\n      <td>120</td>\n      <td>10</td>\n      <td>0.961534</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>softplus</td>\n      <td>130</td>\n      <td>10</td>\n      <td>0.963043</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>softplus</td>\n      <td>140</td>\n      <td>10</td>\n      <td>0.962995</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>softplus</td>\n      <td>150</td>\n      <td>10</td>\n      <td>0.958927</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>softplus</td>\n      <td>160</td>\n      <td>10</td>\n      <td>0.957555</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>softplus</td>\n      <td>170</td>\n      <td>10</td>\n      <td>0.961822</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>softplus</td>\n      <td>180</td>\n      <td>10</td>\n      <td>0.960407</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>softplus</td>\n      <td>190</td>\n      <td>10</td>\n      <td>0.962330</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>softplus</td>\n      <td>200</td>\n      <td>10</td>\n      <td>0.958215</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(params), pd.DataFrame({'model__first_layer_nodes': [20] * len(params)}),pd.DataFrame(means, columns=['R2'])], axis =1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:20:21.434588800Z",
     "start_time": "2023-12-26T15:20:21.393160100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merge all files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#Access input folder\n",
    "input_dir = Path (\"Pressure_hyperparameter_tuning_3layers\")\n",
    "print (\"1\",input_dir)\n",
    "\n",
    "# Output Excel file\n",
    "output_excel_file = Path(\"Pressure_hyperparameter_tuning_3layers/S1_summary_3layers.xlsx\")\n",
    "\n",
    "# List to store DataFrames from CSV files\n",
    "dfs = []\n",
    "\n",
    "# Loop through CSV files in the directory\n",
    "for csv_file in input_dir.glob('*.csv'):\n",
    "    # Read CSV file into a DataFrame and append to the list\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate DataFrames in the list along rows\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Write the merged DataFrame to an Excel file\n",
    "merged_df.to_excel(output_excel_file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for NumPy\n",
    "np.random.seed(71)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model2():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=40, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=85, activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=130, activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model2 = KerasRegressor(model=create_model2, verbose=0, random_state = 71, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "# define the grid search parameters\n",
    "\n",
    "\n",
    "batch_size = [30,40,50]\n",
    "optimizer = [Adam, Nadam, RMSprop]\n",
    "learning_rate = [ 0.001,0.01, 0.1]\n",
    "epochs = [100, 200, 300, 400, 500]\n",
    "\n",
    "# gridsearch\n",
    "param_grid2 = dict(batch_size=batch_size, optimizer=optimizer, optimizer__learning_rate = learning_rate, epochs = epochs)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=71)\n",
    "grid2 = GridSearchCV(estimator=model2, param_grid=param_grid2, n_jobs=-1, scoring = 'r2', cv=kf)\n",
    "grid_result2 = grid2.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
