{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf",
    "ExecuteTime": {
     "end_time": "2024-04-15T23:55:23.091944900Z",
     "start_time": "2024-04-15T23:55:14.531933200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM",
    "ExecuteTime": {
     "end_time": "2024-04-15T23:55:48.297526100Z",
     "start_time": "2024-04-15T23:55:47.626103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1540 entries, 0 to 1539\n",
      "Data columns (total 5 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Explosive type                   1540 non-null   object \n",
      " 1   Explosive mass                   1540 non-null   float64\n",
      " 2   Perpendicular standoff distance  1540 non-null   float64\n",
      " 3   Incident angle                   1540 non-null   int64  \n",
      " 4   Peak reflected pressure          1540 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 60.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('RPDataset4.xlsx')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T23:55:50.557061Z",
     "start_time": "2024-04-15T23:55:50.535139300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1540 entries, 0 to 1539\n",
      "Data columns (total 6 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Explosive mass                   1540 non-null   float64\n",
      " 1   Perpendicular standoff distance  1540 non-null   float64\n",
      " 2   Incident angle                   1540 non-null   int64  \n",
      " 3   Peak reflected pressure          1540 non-null   float64\n",
      " 4   Explosive type_Composition B     1540 non-null   uint8  \n",
      " 5   Explosive type_TNT               1540 non-null   uint8  \n",
      "dtypes: float64(3), int64(1), uint8(2)\n",
      "memory usage: 51.3 KB\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variable into dummy variables\n",
    "dataset = pd.get_dummies(dataset, columns=['Explosive type'])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T23:55:52.493440200Z",
     "start_time": "2024-04-15T23:55:52.414040100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Explosive mass  Perpendicular standoff distance  Incident angle  \\\n0             0.5                              2.0               0   \n1             0.5                              2.0              15   \n2             0.5                              2.0              30   \n3             0.5                              2.0              45   \n4             0.5                              2.0              60   \n\n   Peak reflected pressure  Explosive type_Composition B  Explosive type_TNT  \n0                  372.527                             0                   1  \n1                  340.888                             0                   1  \n2                  290.136                             0                   1  \n3                  231.318                             0                   1  \n4                  173.479                             0                   1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Explosive mass</th>\n      <th>Perpendicular standoff distance</th>\n      <th>Incident angle</th>\n      <th>Peak reflected pressure</th>\n      <th>Explosive type_Composition B</th>\n      <th>Explosive type_TNT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>372.527</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>2.0</td>\n      <td>15</td>\n      <td>340.888</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>2.0</td>\n      <td>30</td>\n      <td>290.136</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>2.0</td>\n      <td>45</td>\n      <td>231.318</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>2.0</td>\n      <td>60</td>\n      <td>173.479</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T23:55:53.972376Z",
     "start_time": "2024-04-15T23:55:53.940304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1540, 5) (1540,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset[('Peak reflected pressure')]\n",
    "X = dataset.drop('Peak reflected pressure', axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (X.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T23:55:56.200718600Z",
     "start_time": "2024-04-15T23:55:56.126242600Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx",
    "ExecuteTime": {
     "end_time": "2024-04-15T23:55:58.202684700Z",
     "start_time": "2024-04-15T23:55:58.139718500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test,\n",
    "                                                y_test,\n",
    "                                                test_size = 0.5,\n",
    "                                                random_state = 71)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T23:55:59.744244800Z",
     "start_time": "2024-04-15T23:55:59.696563100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:,0:2] = sc.fit_transform(X_train[:, 0:2])\n",
    "print (X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test[:,0:2] = sc.transform(X_test[:, 0:2])\n",
    "print (X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_val[:,0:2] = sc.transform(X_val[:, 0:2])\n",
    "print (X_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1 -Hyperparameter tuning - neurons, activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T04:51:22.442834600Z",
     "start_time": "2024-04-16T04:51:22.439313900Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "# Set seed for NumPy\n",
    "np.random.seed(54)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(54)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n",
    "def create_model1(last_layer_nodes, activation_func):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 50,  input_shape=(X_train.shape[1],), activation=activation_func))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(last_layer_nodes, activation=activation_func))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer1 = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer = optimizer1, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "activation_func = ['relu', 'leaky_relu', 'softplus']\n",
    "last_layer_nodes = [ 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250]\n",
    "\n",
    "param_grid = dict( model__activation_func = activation_func,model__last_layer_nodes = last_layer_nodes)\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model1 = KerasRegressor(model=create_model1, verbose=0, epochs = 100, batch_size = 50, random_state = 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T04:53:35.120417100Z",
     "start_time": "2024-04-16T04:51:24.920212300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.966233 using {'model__activation_func': 'softplus', 'model__last_layer_nodes': 240}\n",
      "0.951139 (0.017617) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 50}\n",
      "0.958039 (0.003363) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 60}\n",
      "0.960362 (0.007333) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 70}\n",
      "0.960693 (0.005830) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 80}\n",
      "0.958709 (0.007823) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 90}\n",
      "0.959726 (0.009271) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 100}\n",
      "0.959961 (0.005092) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 110}\n",
      "0.961138 (0.007601) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 120}\n",
      "0.956575 (0.006156) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 130}\n",
      "0.960229 (0.005745) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 140}\n",
      "0.961775 (0.005652) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 150}\n",
      "0.962288 (0.008061) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 160}\n",
      "0.963616 (0.007666) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 170}\n",
      "0.963503 (0.007602) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 180}\n",
      "0.961596 (0.006638) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 190}\n",
      "0.962487 (0.007840) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 200}\n",
      "0.963803 (0.005111) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 210}\n",
      "0.963449 (0.006201) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 220}\n",
      "0.960765 (0.006409) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 230}\n",
      "0.960327 (0.005883) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 240}\n",
      "0.963668 (0.008178) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 250}\n",
      "0.955737 (0.007118) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 50}\n",
      "0.956534 (0.006786) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 60}\n",
      "0.954869 (0.004963) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 70}\n",
      "0.958450 (0.004352) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 80}\n",
      "0.958973 (0.003666) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 90}\n",
      "0.958989 (0.006576) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 100}\n",
      "0.957662 (0.004122) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 110}\n",
      "0.960810 (0.002989) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 120}\n",
      "0.956986 (0.006268) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 130}\n",
      "0.958595 (0.005552) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 140}\n",
      "0.960090 (0.003986) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 150}\n",
      "0.955333 (0.007255) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 160}\n",
      "0.959175 (0.004642) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 170}\n",
      "0.958519 (0.004727) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 180}\n",
      "0.961027 (0.004891) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 190}\n",
      "0.958192 (0.004732) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 200}\n",
      "0.960147 (0.004031) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 210}\n",
      "0.959014 (0.003564) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 220}\n",
      "0.959380 (0.003868) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 230}\n",
      "0.958707 (0.005111) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 240}\n",
      "0.961190 (0.004890) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 250}\n",
      "0.960981 (0.008338) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 50}\n",
      "0.960026 (0.006790) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 60}\n",
      "0.959239 (0.005509) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 70}\n",
      "0.961457 (0.008151) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 80}\n",
      "0.961333 (0.009291) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 90}\n",
      "0.960287 (0.005319) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 100}\n",
      "0.961042 (0.006486) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 110}\n",
      "0.963068 (0.007872) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 120}\n",
      "0.958743 (0.006883) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 130}\n",
      "0.959712 (0.005269) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 140}\n",
      "0.960210 (0.006227) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 150}\n",
      "0.962622 (0.004608) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 160}\n",
      "0.960356 (0.005105) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 170}\n",
      "0.960784 (0.008144) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 180}\n",
      "0.961714 (0.007692) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 190}\n",
      "0.964807 (0.008208) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 200}\n",
      "0.960543 (0.005179) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 210}\n",
      "0.964460 (0.004272) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 220}\n",
      "0.964531 (0.007343) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 230}\n",
      "0.966233 (0.005639) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 240}\n",
      "0.963247 (0.006033) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 250}\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=54)\n",
    "grid1 = GridSearchCV(estimator = model1, param_grid= param_grid, n_jobs=-1, scoring = 'r2', cv=kf)\n",
    "grid_result1 = grid1.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "   model__activation_func  model__last_layer_nodes  model__first_layer_nodes  \\\n0                    relu                       50                        50   \n1                    relu                       60                        50   \n2                    relu                       70                        50   \n3                    relu                       80                        50   \n4                    relu                       90                        50   \n..                    ...                      ...                       ...   \n58               softplus                      210                        50   \n59               softplus                      220                        50   \n60               softplus                      230                        50   \n61               softplus                      240                        50   \n62               softplus                      250                        50   \n\n          R2  \n0   0.951139  \n1   0.958039  \n2   0.960362  \n3   0.960693  \n4   0.958709  \n..       ...  \n58  0.960543  \n59  0.964460  \n60  0.964531  \n61  0.966233  \n62  0.963247  \n\n[63 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model__activation_func</th>\n      <th>model__last_layer_nodes</th>\n      <th>model__first_layer_nodes</th>\n      <th>R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>relu</td>\n      <td>50</td>\n      <td>50</td>\n      <td>0.951139</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>relu</td>\n      <td>60</td>\n      <td>50</td>\n      <td>0.958039</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>relu</td>\n      <td>70</td>\n      <td>50</td>\n      <td>0.960362</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>relu</td>\n      <td>80</td>\n      <td>50</td>\n      <td>0.960693</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>relu</td>\n      <td>90</td>\n      <td>50</td>\n      <td>0.958709</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>softplus</td>\n      <td>210</td>\n      <td>50</td>\n      <td>0.960543</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>softplus</td>\n      <td>220</td>\n      <td>50</td>\n      <td>0.964460</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>softplus</td>\n      <td>230</td>\n      <td>50</td>\n      <td>0.964531</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>softplus</td>\n      <td>240</td>\n      <td>50</td>\n      <td>0.966233</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>softplus</td>\n      <td>250</td>\n      <td>50</td>\n      <td>0.963247</td>\n    </tr>\n  </tbody>\n</table>\n<p>63 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(params), pd.DataFrame({'model__first_layer_nodes': [50] * len(params)}),pd.DataFrame(means, columns=['R2'])], axis =1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T05:06:45.834211800Z",
     "start_time": "2024-04-16T05:06:45.802825500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merge all files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 G:\\Chamodi\\1D_Tracers\\Hyperparameter tuning summary_ANN\\Reflected_pressure_hyperparameter_tuning4\n",
      "[     0         1    2    3         4\n",
      "0    0      relu   50  100  0.962207\n",
      "1    1      relu   60  100  0.960829\n",
      "2    2      relu   70  100  0.954493\n",
      "3    3      relu   80  100  0.963898\n",
      "4    4      relu   90  100  0.963209\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  100  0.961156\n",
      "59  59  softplus  220  100  0.959963\n",
      "60  60  softplus  230  100  0.961195\n",
      "61  61  softplus  240  100  0.961925\n",
      "62  62  softplus  250  100  0.961607\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  110  0.955566\n",
      "1    1      relu   60  110  0.963125\n",
      "2    2      relu   70  110  0.951621\n",
      "3    3      relu   80  110  0.963335\n",
      "4    4      relu   90  110  0.964423\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  110  0.961259\n",
      "59  59  softplus  220  110  0.960277\n",
      "60  60  softplus  230  110  0.961853\n",
      "61  61  softplus  240  110  0.962990\n",
      "62  62  softplus  250  110  0.963800\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  120  0.959722\n",
      "1    1      relu   60  120  0.962749\n",
      "2    2      relu   70  120  0.963209\n",
      "3    3      relu   80  120  0.961249\n",
      "4    4      relu   90  120  0.963886\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  120  0.962683\n",
      "59  59  softplus  220  120  0.958227\n",
      "60  60  softplus  230  120  0.961339\n",
      "61  61  softplus  240  120  0.960599\n",
      "62  62  softplus  250  120  0.962045\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  130  0.962445\n",
      "1    1      relu   60  130  0.961854\n",
      "2    2      relu   70  130  0.963251\n",
      "3    3      relu   80  130  0.961899\n",
      "4    4      relu   90  130  0.964970\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  130  0.963719\n",
      "59  59  softplus  220  130  0.962055\n",
      "60  60  softplus  230  130  0.963603\n",
      "61  61  softplus  240  130  0.962970\n",
      "62  62  softplus  250  130  0.964008\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  140  0.963398\n",
      "1    1      relu   60  140  0.959695\n",
      "2    2      relu   70  140  0.963712\n",
      "3    3      relu   80  140  0.963494\n",
      "4    4      relu   90  140  0.965801\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  140  0.962364\n",
      "59  59  softplus  220  140  0.962015\n",
      "60  60  softplus  230  140  0.959686\n",
      "61  61  softplus  240  140  0.958699\n",
      "62  62  softplus  250  140  0.961176\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  150  0.955417\n",
      "1    1      relu   60  150  0.963414\n",
      "2    2      relu   70  150  0.958801\n",
      "3    3      relu   80  150  0.961281\n",
      "4    4      relu   90  150  0.963166\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  150  0.965538\n",
      "59  59  softplus  220  150  0.963460\n",
      "60  60  softplus  230  150  0.962967\n",
      "61  61  softplus  240  150  0.964662\n",
      "62  62  softplus  250  150  0.954838\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  160  0.960500\n",
      "1    1      relu   60  160  0.963091\n",
      "2    2      relu   70  160  0.963787\n",
      "3    3      relu   80  160  0.962617\n",
      "4    4      relu   90  160  0.964538\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  160  0.961849\n",
      "59  59  softplus  220  160  0.962689\n",
      "60  60  softplus  230  160  0.961729\n",
      "61  61  softplus  240  160  0.962525\n",
      "62  62  softplus  250  160  0.962462\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  170  0.961834\n",
      "1    1      relu   60  170  0.963467\n",
      "2    2      relu   70  170  0.961704\n",
      "3    3      relu   80  170  0.962142\n",
      "4    4      relu   90  170  0.962697\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  170  0.960403\n",
      "59  59  softplus  220  170  0.963277\n",
      "60  60  softplus  230  170  0.961841\n",
      "61  61  softplus  240  170  0.961481\n",
      "62  62  softplus  250  170  0.962059\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  180  0.962176\n",
      "1    1      relu   60  180  0.963495\n",
      "2    2      relu   70  180  0.963374\n",
      "3    3      relu   80  180  0.964684\n",
      "4    4      relu   90  180  0.965114\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  180  0.960267\n",
      "59  59  softplus  220  180  0.963889\n",
      "60  60  softplus  230  180  0.963402\n",
      "61  61  softplus  240  180  0.964300\n",
      "62  62  softplus  250  180  0.963635\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  190  0.962479\n",
      "1    1      relu   60  190  0.963942\n",
      "2    2      relu   70  190  0.963604\n",
      "3    3      relu   80  190  0.966721\n",
      "4    4      relu   90  190  0.963679\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  190  0.963005\n",
      "59  59  softplus  220  190  0.961801\n",
      "60  60  softplus  230  190  0.964767\n",
      "61  61  softplus  240  190  0.961477\n",
      "62  62  softplus  250  190  0.963169\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  200  0.964200\n",
      "1    1      relu   60  200  0.962877\n",
      "2    2      relu   70  200  0.964169\n",
      "3    3      relu   80  200  0.963176\n",
      "4    4      relu   90  200  0.966509\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  200  0.962791\n",
      "59  59  softplus  220  200  0.963288\n",
      "60  60  softplus  230  200  0.962696\n",
      "61  61  softplus  240  200  0.963277\n",
      "62  62  softplus  250  200  0.964174\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  210  0.962315\n",
      "1    1      relu   60  210  0.964801\n",
      "2    2      relu   70  210  0.964290\n",
      "3    3      relu   80  210  0.963762\n",
      "4    4      relu   90  210  0.964741\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  210  0.960777\n",
      "59  59  softplus  220  210  0.961528\n",
      "60  60  softplus  230  210  0.962436\n",
      "61  61  softplus  240  210  0.961322\n",
      "62  62  softplus  250  210  0.962198\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  220  0.961996\n",
      "1    1      relu   60  220  0.963686\n",
      "2    2      relu   70  220  0.962106\n",
      "3    3      relu   80  220  0.965092\n",
      "4    4      relu   90  220  0.963629\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  220  0.962584\n",
      "59  59  softplus  220  220  0.961178\n",
      "60  60  softplus  230  220  0.961942\n",
      "61  61  softplus  240  220  0.962449\n",
      "62  62  softplus  250  220  0.951396\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  230  0.962034\n",
      "1    1      relu   60  230  0.962345\n",
      "2    2      relu   70  230  0.963114\n",
      "3    3      relu   80  230  0.961898\n",
      "4    4      relu   90  230  0.963047\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  230  0.962728\n",
      "59  59  softplus  220  230  0.961433\n",
      "60  60  softplus  230  230  0.962780\n",
      "61  61  softplus  240  230  0.963088\n",
      "62  62  softplus  250  230  0.962770\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  240  0.964201\n",
      "1    1      relu   60  240  0.962394\n",
      "2    2      relu   70  240  0.963496\n",
      "3    3      relu   80  240  0.963636\n",
      "4    4      relu   90  240  0.966646\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  240  0.962755\n",
      "59  59  softplus  220  240  0.962259\n",
      "60  60  softplus  230  240  0.961778\n",
      "61  61  softplus  240  240  0.962618\n",
      "62  62  softplus  250  240  0.962888\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  250  0.963508\n",
      "1    1      relu   60  250  0.962806\n",
      "2    2      relu   70  250  0.965332\n",
      "3    3      relu   80  250  0.964370\n",
      "4    4      relu   90  250  0.963753\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  250  0.961691\n",
      "59  59  softplus  220  250  0.962436\n",
      "60  60  softplus  230  250  0.961719\n",
      "61  61  softplus  240  250  0.963005\n",
      "62  62  softplus  250  250  0.964978\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2   3         4\n",
      "0    0      relu   50  50  0.951139\n",
      "1    1      relu   60  50  0.958039\n",
      "2    2      relu   70  50  0.960362\n",
      "3    3      relu   80  50  0.960693\n",
      "4    4      relu   90  50  0.958709\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  50  0.960543\n",
      "59  59  softplus  220  50  0.964460\n",
      "60  60  softplus  230  50  0.964531\n",
      "61  61  softplus  240  50  0.966233\n",
      "62  62  softplus  250  50  0.963247\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2   3         4\n",
      "0    0      relu   50  60  0.947044\n",
      "1    1      relu   60  60  0.950540\n",
      "2    2      relu   70  60  0.951583\n",
      "3    3      relu   80  60  0.953184\n",
      "4    4      relu   90  60  0.961471\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  60  0.958918\n",
      "59  59  softplus  220  60  0.960982\n",
      "60  60  softplus  230  60  0.963416\n",
      "61  61  softplus  240  60  0.958104\n",
      "62  62  softplus  250  60  0.963648\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2   3         4\n",
      "0    0      relu   50  70  0.960763\n",
      "1    1      relu   60  70  0.959737\n",
      "2    2      relu   70  70  0.961077\n",
      "3    3      relu   80  70  0.957619\n",
      "4    4      relu   90  70  0.963697\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  70  0.963713\n",
      "59  59  softplus  220  70  0.961807\n",
      "60  60  softplus  230  70  0.961449\n",
      "61  61  softplus  240  70  0.963054\n",
      "62  62  softplus  250  70  0.960927\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2   3         4\n",
      "0    0      relu   50  80  0.963888\n",
      "1    1      relu   60  80  0.960991\n",
      "2    2      relu   70  80  0.960155\n",
      "3    3      relu   80  80  0.962668\n",
      "4    4      relu   90  80  0.963505\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  80  0.960728\n",
      "59  59  softplus  220  80  0.960223\n",
      "60  60  softplus  230  80  0.961966\n",
      "61  61  softplus  240  80  0.959237\n",
      "62  62  softplus  250  80  0.963008\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2   3         4\n",
      "0    0      relu   50  90  0.955400\n",
      "1    1      relu   60  90  0.963584\n",
      "2    2      relu   70  90  0.963583\n",
      "3    3      relu   80  90  0.960776\n",
      "4    4      relu   90  90  0.964272\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  90  0.961595\n",
      "59  59  softplus  220  90  0.959523\n",
      "60  60  softplus  230  90  0.960191\n",
      "61  61  softplus  240  90  0.960495\n",
      "62  62  softplus  250  90  0.960673\n",
      "\n",
      "[63 rows x 5 columns]]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "redirect_dir = current_dir.parent.parent.parent\n",
    "\n",
    "#Access input folder\n",
    "input_dir = Path (redirect_dir/\"1D_Tracers/Hyperparameter tuning summary_ANN/Reflected_pressure_hyperparameter_tuning4\")\n",
    "print (\"1\",input_dir)\n",
    "\n",
    "# Output Excel file\n",
    "output_excel_file = Path(input_dir/\"S1_summary.xlsx\")\n",
    "\n",
    "# List to store DataFrames from CSV files\n",
    "dfs = []\n",
    "\n",
    "# Loop through CSV files in the directory\n",
    "for csv_file in input_dir.glob('*.csv'):\n",
    "    # Read CSV file into a DataFrame and append to the list\n",
    "    df = pd.read_csv(csv_file, header = None)\n",
    "    dfs.append(df)\n",
    "\n",
    "print (dfs)\n",
    "\n",
    "# Concatenate DataFrames in the list along rows\n",
    "merged_df = pd.concat(dfs, axis = 0,ignore_index=False)\n",
    "\n",
    "# Write the merged DataFrame to an Excel file\n",
    "merged_df.to_excel(output_excel_file, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T05:08:26.312709700Z",
     "start_time": "2024-04-16T05:08:25.926775100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### S2 - Hyperparameter tuning - batch size, epoch, optimizer, learning rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Nadam\n",
    "# Set seed for NumPy\n",
    "np.random.seed(54)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(54)\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model2():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=210, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=210, activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    " return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T05:09:49.138625Z",
     "start_time": "2024-04-16T05:09:49.138625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.974955 using {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.969364 (0.004384) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.972086 (0.009706) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.948065 (0.012732) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.972664 (0.004347) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.972204 (0.004602) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.957953 (0.010367) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.965841 (0.012245) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.971515 (0.008375) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.955796 (0.010025) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.969755 (0.004065) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.973736 (0.006590) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.965888 (0.010750) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.970994 (0.002964) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.974075 (0.005742) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.970741 (0.006143) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.964350 (0.013738) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.973753 (0.011058) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.947994 (0.030615) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.968945 (0.003454) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.969403 (0.015096) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.964551 (0.009057) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.969865 (0.002673) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.974955 (0.005398) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.962241 (0.015244) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.964341 (0.001966) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.950506 (0.027750) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.936037 (0.036459) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model2 = KerasRegressor(model=create_model2, verbose=0, random_state = 54, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [30,40,50]\n",
    "optimizer = [Adam, Nadam, RMSprop]\n",
    "learning_rate = [ 0.001,0.01, 0.1]\n",
    "epochs = [500]\n",
    "\n",
    "# gridsearch\n",
    "param_grid2 = dict(batch_size=batch_size, optimizer=optimizer, optimizer__learning_rate = learning_rate, epochs = epochs)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=54)\n",
    "grid2 = GridSearchCV(estimator=model2, param_grid=param_grid2, n_jobs=-1, scoring = 'r2', cv=kf)\n",
    "grid_result2 = grid2.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T05:14:51.110437200Z",
     "start_time": "2024-04-16T05:10:01.435741400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "    batch_size  epochs                                       optimizer  \\\n0           30     500        <class 'keras.src.optimizers.adam.Adam'>   \n1           30     500        <class 'keras.src.optimizers.adam.Adam'>   \n2           30     500        <class 'keras.src.optimizers.adam.Adam'>   \n3           30     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n4           30     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n5           30     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n6           30     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n7           30     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n8           30     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n9           40     500        <class 'keras.src.optimizers.adam.Adam'>   \n10          40     500        <class 'keras.src.optimizers.adam.Adam'>   \n11          40     500        <class 'keras.src.optimizers.adam.Adam'>   \n12          40     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n13          40     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n14          40     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n15          40     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n16          40     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n17          40     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n18          50     500        <class 'keras.src.optimizers.adam.Adam'>   \n19          50     500        <class 'keras.src.optimizers.adam.Adam'>   \n20          50     500        <class 'keras.src.optimizers.adam.Adam'>   \n21          50     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n22          50     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n23          50     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n24          50     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n25          50     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n26          50     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n\n    optimizer__learning_rate        R2  \n0                      0.001  0.969364  \n1                      0.010  0.972086  \n2                      0.100  0.948065  \n3                      0.001  0.972664  \n4                      0.010  0.972204  \n5                      0.100  0.957953  \n6                      0.001  0.965841  \n7                      0.010  0.971515  \n8                      0.100  0.955796  \n9                      0.001  0.969755  \n10                     0.010  0.973736  \n11                     0.100  0.965888  \n12                     0.001  0.970994  \n13                     0.010  0.974075  \n14                     0.100  0.970741  \n15                     0.001  0.964350  \n16                     0.010  0.973753  \n17                     0.100  0.947994  \n18                     0.001  0.968945  \n19                     0.010  0.969403  \n20                     0.100  0.964551  \n21                     0.001  0.969865  \n22                     0.010  0.974955  \n23                     0.100  0.962241  \n24                     0.001  0.964341  \n25                     0.010  0.950506  \n26                     0.100  0.936037  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>batch_size</th>\n      <th>epochs</th>\n      <th>optimizer</th>\n      <th>optimizer__learning_rate</th>\n      <th>R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.001</td>\n      <td>0.969364</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.010</td>\n      <td>0.972086</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.100</td>\n      <td>0.948065</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.001</td>\n      <td>0.972664</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.010</td>\n      <td>0.972204</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.100</td>\n      <td>0.957953</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.001</td>\n      <td>0.965841</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.010</td>\n      <td>0.971515</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.100</td>\n      <td>0.955796</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.001</td>\n      <td>0.969755</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.010</td>\n      <td>0.973736</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.100</td>\n      <td>0.965888</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.001</td>\n      <td>0.970994</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.010</td>\n      <td>0.974075</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.100</td>\n      <td>0.970741</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.001</td>\n      <td>0.964350</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.010</td>\n      <td>0.973753</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.100</td>\n      <td>0.947994</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.001</td>\n      <td>0.968945</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.010</td>\n      <td>0.969403</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.100</td>\n      <td>0.964551</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.001</td>\n      <td>0.969865</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.010</td>\n      <td>0.974955</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.100</td>\n      <td>0.962241</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.001</td>\n      <td>0.964341</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.010</td>\n      <td>0.950506</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.100</td>\n      <td>0.936037</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(params), pd.DataFrame(means, columns=['R2'])], axis =1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T05:24:05.921988200Z",
     "start_time": "2024-04-16T05:24:05.858413500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_result2.best_params_\n",
    "print (best_params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the final model using the best hyperparameters\n",
    "final_model = KerasRegressor(\n",
    "    build_fn=create_model2,\n",
    "    verbose=0,\n",
    "    random_state=71,\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae'],\n",
    "    optimizer = Adam,\n",
    "    optimizer__learning_rate = 0.1\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   mode='min',\n",
    "                   patience=50,\n",
    "                   restore_best_weights = True)\n",
    "# Train the final model on the entire training set\n",
    "history = final_model.fit(X_train, y_train,\n",
    "                validation_data = (X_val, y_val),\n",
    "                callbacks=[es],\n",
    "                epochs=best_params['epochs'],\n",
    "                batch_size=best_params['batch_size'],\n",
    "                verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyse learn history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's see the training and validation accuracy by epoch\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss'] # you can change this\n",
    "val_loss_values = history_dict['val_loss'] # you can also change this\n",
    "epochs = range(1, len(loss_values) + 1) # range of X (no. of epochs)\n",
    "plt.plot(epochs, loss_values, 'blue', label='Train set loss')\n",
    "plt.plot(epochs, val_loss_values, 'orange', label='Validation set loss')\n",
    "#plt.title('Training and testing loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_values1 = history_dict['mae'] # you can change this\n",
    "val_loss_values1 = history_dict['val_mae'] # you can also change this\n",
    "epochs = range(1, len(loss_values1) + 1) # range of X (no. of epochs)\n",
    "plt.plot(epochs, loss_values1, 'blue', label='Train set MAE')\n",
    "plt.plot(epochs, val_loss_values1, 'orange', label='Validation set MAE')\n",
    "#plt.title('Training and testing MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
