{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf",
    "ExecuteTime": {
     "end_time": "2024-02-06T00:55:04.835472900Z",
     "start_time": "2024-02-06T00:54:57.430528200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM",
    "ExecuteTime": {
     "end_time": "2024-02-06T00:55:09.212863900Z",
     "start_time": "2024-02-06T00:55:08.696335700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588 entries, 0 to 587\n",
      "Data columns (total 4 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Explosive type                588 non-null    object \n",
      " 1   Explosive mass(kg)            588 non-null    float64\n",
      " 2   Standoff distance(m)          588 non-null    float64\n",
      " 3   Peak reflected pressure(kPa)  588 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 18.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('RPDataset1.xlsx')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:55:24.455002900Z",
     "start_time": "2024-02-06T00:55:24.429160100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588 entries, 0 to 587\n",
      "Data columns (total 5 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Explosive mass(kg)            588 non-null    float64\n",
      " 1   Standoff distance(m)          588 non-null    float64\n",
      " 2   Peak reflected pressure(kPa)  588 non-null    float64\n",
      " 3   Explosive type_Composition B  588 non-null    uint8  \n",
      " 4   Explosive type_TNT            588 non-null    uint8  \n",
      "dtypes: float64(3), uint8(2)\n",
      "memory usage: 15.1 KB\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variable into dummy variables\n",
    "dataset = pd.get_dummies(dataset, columns=['Explosive type'])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:55:28.976611400Z",
     "start_time": "2024-02-06T00:55:28.947779800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Explosive mass(kg)  Standoff distance(m)  Peak reflected pressure(kPa)  \\\n0                 0.5                   1.5                     849.52040   \n1                 0.5                  10.5                     116.73901   \n2                 0.5                  11.5                     114.90842   \n3                 0.5                  12.5                     113.43890   \n4                 0.5                  13.5                     112.23654   \n\n   Explosive type_Composition B  Explosive type_TNT  \n0                             1                   0  \n1                             1                   0  \n2                             1                   0  \n3                             1                   0  \n4                             1                   0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Explosive mass(kg)</th>\n      <th>Standoff distance(m)</th>\n      <th>Peak reflected pressure(kPa)</th>\n      <th>Explosive type_Composition B</th>\n      <th>Explosive type_TNT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>1.5</td>\n      <td>849.52040</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>10.5</td>\n      <td>116.73901</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>11.5</td>\n      <td>114.90842</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>12.5</td>\n      <td>113.43890</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>13.5</td>\n      <td>112.23654</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:55:39.146639400Z",
     "start_time": "2024-02-06T00:55:39.115586100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588, 4) (588,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset[('Peak reflected pressure(kPa)')]\n",
    "X = dataset.drop('Peak reflected pressure(kPa)', axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Explosive mass(kg)  Standoff distance(m)  Explosive type_Composition B  \\\n",
      "0                 0.5                   1.5                             1   \n",
      "1                 0.5                  10.5                             1   \n",
      "2                 0.5                  11.5                             1   \n",
      "3                 0.5                  12.5                             1   \n",
      "4                 0.5                  13.5                             1   \n",
      "\n",
      "   Explosive type_TNT  \n",
      "0                   0  \n",
      "1                   0  \n",
      "2                   0  \n",
      "3                   0  \n",
      "4                   0  \n"
     ]
    }
   ],
   "source": [
    "print (X.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:55:56.762614400Z",
     "start_time": "2024-02-06T00:55:56.736391900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0    849.52040\n1    116.73901\n2    114.90842\n3    113.43890\n4    112.23654\nName: Peak reflected pressure(kPa), dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:56:16.875869Z",
     "start_time": "2024-02-06T00:56:16.852826500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T00:56:25.252065100Z",
     "start_time": "2024-02-06T00:56:25.227868200Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx",
    "ExecuteTime": {
     "end_time": "2024-02-06T00:56:32.129841700Z",
     "start_time": "2024-02-06T00:56:32.106189200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test,\n",
    "                                                y_test,\n",
    "                                                test_size = 0.5,\n",
    "                                                random_state = 71)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T00:56:33.725896400Z",
     "start_time": "2024-02-06T00:56:33.699749100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:,0:2] = sc.fit_transform(X_train[:, 0:2])\n",
    "print (X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test[:,0:2] = sc.transform(X_test[:, 0:2])\n",
    "print (X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_val[:,0:2] = sc.transform(X_val[:, 0:2])\n",
    "print (X_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1 -Hyperparameter tuning - neurons, activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T03:30:50.088375800Z",
     "start_time": "2024-02-06T03:30:50.065832300Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "# Set seed for NumPy\n",
    "np.random.seed(54)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(54)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n",
    "def create_model1(last_layer_nodes, activation_func):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 250,  input_shape=(X_train.shape[1],), activation=activation_func))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(last_layer_nodes, activation=activation_func))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer1 = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer = optimizer1, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "activation_func = ['relu', 'leaky_relu', 'softplus']\n",
    "last_layer_nodes = [50,60, 70, 80,90,100,110,120,130, 140, 150,160, 170, 180, 190, 200, 210, 220, 230, 240, 250]\n",
    "\n",
    "param_grid = dict( model__activation_func = activation_func,model__last_layer_nodes = last_layer_nodes)\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model1 = KerasRegressor(model=create_model1, verbose=0, epochs = 100, batch_size = 50, random_state = 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T03:31:55.051082700Z",
     "start_time": "2024-02-06T03:30:52.655028700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.965583 using {'model__activation_func': 'relu', 'model__last_layer_nodes': 210}\n",
      "0.931790 (0.066760) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 50}\n",
      "0.947392 (0.044960) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 60}\n",
      "0.944336 (0.050107) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 70}\n",
      "0.954378 (0.026744) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 80}\n",
      "0.952455 (0.028046) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 90}\n",
      "0.928899 (0.057181) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 100}\n",
      "0.960983 (0.020133) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 110}\n",
      "0.955239 (0.026119) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 120}\n",
      "0.959856 (0.020881) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 130}\n",
      "0.957367 (0.022299) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 140}\n",
      "0.953710 (0.025412) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 150}\n",
      "0.959351 (0.018961) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 160}\n",
      "0.962139 (0.016381) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 170}\n",
      "0.959366 (0.019709) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 180}\n",
      "0.962620 (0.019317) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 190}\n",
      "0.961703 (0.019376) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 200}\n",
      "0.965583 (0.012995) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 210}\n",
      "0.963542 (0.019505) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 220}\n",
      "0.961468 (0.021393) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 230}\n",
      "0.959446 (0.022272) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 240}\n",
      "0.962788 (0.018617) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 250}\n",
      "0.920067 (0.078319) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 50}\n",
      "0.925192 (0.069385) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 60}\n",
      "0.927977 (0.062637) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 70}\n",
      "0.933441 (0.053506) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 80}\n",
      "0.940017 (0.044829) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 90}\n",
      "0.942553 (0.042720) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 100}\n",
      "0.945407 (0.038435) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 110}\n",
      "0.948999 (0.036207) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 120}\n",
      "0.949962 (0.034192) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 130}\n",
      "0.951438 (0.032805) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 140}\n",
      "0.951139 (0.033716) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 150}\n",
      "0.953041 (0.031492) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 160}\n",
      "0.953552 (0.030231) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 170}\n",
      "0.953370 (0.030920) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 180}\n",
      "0.954472 (0.030136) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 190}\n",
      "0.953744 (0.030073) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 200}\n",
      "0.954335 (0.031665) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 210}\n",
      "0.954772 (0.030299) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 220}\n",
      "0.953687 (0.031718) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 230}\n",
      "0.954489 (0.031343) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 240}\n",
      "0.955823 (0.028771) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 250}\n",
      "0.929786 (0.061131) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 50}\n",
      "0.933010 (0.053731) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 60}\n",
      "0.934854 (0.050245) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 70}\n",
      "0.936190 (0.047353) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 80}\n",
      "0.938158 (0.043660) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 90}\n",
      "0.939140 (0.041749) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 100}\n",
      "0.940814 (0.038615) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 110}\n",
      "0.942016 (0.036395) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 120}\n",
      "0.943206 (0.034479) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 130}\n",
      "0.944256 (0.032875) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 140}\n",
      "0.944773 (0.031879) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 150}\n",
      "0.945684 (0.030438) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 160}\n",
      "0.946334 (0.029544) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 170}\n",
      "0.946505 (0.028557) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 180}\n",
      "0.947548 (0.027516) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 190}\n",
      "0.948265 (0.026270) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 200}\n",
      "0.949144 (0.024981) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 210}\n",
      "0.949310 (0.024219) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 220}\n",
      "0.950075 (0.023367) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 230}\n",
      "0.950537 (0.022281) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 240}\n",
      "0.953523 (0.024970) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 250}\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=54)\n",
    "grid1 = GridSearchCV(estimator = model1, param_grid= param_grid, n_jobs=-1, scoring = 'r2', cv=kf)\n",
    "grid_result1 = grid1.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "   model__activation_func  model__last_layer_nodes  model__first_layer_nodes  \\\n0                    relu                       50                       250   \n1                    relu                       60                       250   \n2                    relu                       70                       250   \n3                    relu                       80                       250   \n4                    relu                       90                       250   \n..                    ...                      ...                       ...   \n58               softplus                      210                       250   \n59               softplus                      220                       250   \n60               softplus                      230                       250   \n61               softplus                      240                       250   \n62               softplus                      250                       250   \n\n          R2  \n0   0.931790  \n1   0.947392  \n2   0.944336  \n3   0.954378  \n4   0.952455  \n..       ...  \n58  0.949144  \n59  0.949310  \n60  0.950075  \n61  0.950537  \n62  0.953523  \n\n[63 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model__activation_func</th>\n      <th>model__last_layer_nodes</th>\n      <th>model__first_layer_nodes</th>\n      <th>R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>relu</td>\n      <td>50</td>\n      <td>250</td>\n      <td>0.931790</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>relu</td>\n      <td>60</td>\n      <td>250</td>\n      <td>0.947392</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>relu</td>\n      <td>70</td>\n      <td>250</td>\n      <td>0.944336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>relu</td>\n      <td>80</td>\n      <td>250</td>\n      <td>0.954378</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>relu</td>\n      <td>90</td>\n      <td>250</td>\n      <td>0.952455</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>softplus</td>\n      <td>210</td>\n      <td>250</td>\n      <td>0.949144</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>softplus</td>\n      <td>220</td>\n      <td>250</td>\n      <td>0.949310</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>softplus</td>\n      <td>230</td>\n      <td>250</td>\n      <td>0.950075</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>softplus</td>\n      <td>240</td>\n      <td>250</td>\n      <td>0.950537</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>softplus</td>\n      <td>250</td>\n      <td>250</td>\n      <td>0.953523</td>\n    </tr>\n  </tbody>\n</table>\n<p>63 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(params), pd.DataFrame({'model__first_layer_nodes': [250] * len(params)}),pd.DataFrame(means, columns=['R2'])], axis =1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T03:32:03.093341600Z",
     "start_time": "2024-02-06T03:32:03.064732600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merge all files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 G:\\Chamodi\\1D_Tracers\\Hyperparameter tuning summary_ANN\\Reflected_pressure_hyperparameter_tuning2\n",
      "[     0         1    2   3         4\n",
      "0    0      relu   50  50  0.866445\n",
      "1    1      relu   60  50  0.879698\n",
      "2    2      relu   70  50  0.898776\n",
      "3    3      relu   80  50  0.883987\n",
      "4    4      relu   90  50  0.897611\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  50  0.927736\n",
      "59  59  softplus  220  50  0.930607\n",
      "60  60  softplus  230  50  0.928415\n",
      "61  61  softplus  240  50  0.933343\n",
      "62  62  softplus  250  50  0.932596\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  140  0.924321\n",
      "1    1      relu   60  140  0.917221\n",
      "2    2      relu   70  140  0.914532\n",
      "3    3      relu   80  140  0.921420\n",
      "4    4      relu   90  140  0.925865\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  140  0.937001\n",
      "59  59  softplus  220  140  0.943296\n",
      "60  60  softplus  230  140  0.946155\n",
      "61  61  softplus  240  140  0.956641\n",
      "62  62  softplus  250  140  0.962699\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  150  0.920354\n",
      "1    1      relu   60  150  0.916989\n",
      "2    2      relu   70  150  0.919957\n",
      "3    3      relu   80  150  0.931362\n",
      "4    4      relu   90  150  0.930445\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  150  0.939794\n",
      "59  59  softplus  220  150  0.943949\n",
      "60  60  softplus  230  150  0.943020\n",
      "61  61  softplus  240  150  0.943760\n",
      "62  62  softplus  250  150  0.945902\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  160  0.927124\n",
      "1    1      relu   60  160  0.925920\n",
      "2    2      relu   70  160  0.927814\n",
      "3    3      relu   80  160  0.922861\n",
      "4    4      relu   90  160  0.924439\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  160  0.943551\n",
      "59  59  softplus  220  160  0.957274\n",
      "60  60  softplus  230  160  0.944494\n",
      "61  61  softplus  240  160  0.942486\n",
      "62  62  softplus  250  160  0.942701\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  170  0.925613\n",
      "1    1      relu   60  170  0.929517\n",
      "2    2      relu   70  170  0.936755\n",
      "3    3      relu   80  170  0.908387\n",
      "4    4      relu   90  170  0.938683\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  170  0.944156\n",
      "59  59  softplus  220  170  0.945256\n",
      "60  60  softplus  230  170  0.943558\n",
      "61  61  softplus  240  170  0.945156\n",
      "62  62  softplus  250  170  0.946264\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  180  0.927416\n",
      "1    1      relu   60  180  0.924342\n",
      "2    2      relu   70  180  0.928802\n",
      "3    3      relu   80  180  0.932244\n",
      "4    4      relu   90  180  0.936438\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  180  0.945204\n",
      "59  59  softplus  220  180  0.942496\n",
      "60  60  softplus  230  180  0.942987\n",
      "61  61  softplus  240  180  0.948615\n",
      "62  62  softplus  250  180  0.960350\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  190  0.929770\n",
      "1    1      relu   60  190  0.926338\n",
      "2    2      relu   70  190  0.936981\n",
      "3    3      relu   80  190  0.918950\n",
      "4    4      relu   90  190  0.935436\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  190  0.947947\n",
      "59  59  softplus  220  190  0.944345\n",
      "60  60  softplus  230  190  0.948367\n",
      "61  61  softplus  240  190  0.959037\n",
      "62  62  softplus  250  190  0.944791\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  200  0.917376\n",
      "1    1      relu   60  200  0.919760\n",
      "2    2      relu   70  200  0.937505\n",
      "3    3      relu   80  200  0.937696\n",
      "4    4      relu   90  200  0.928292\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  200  0.948724\n",
      "59  59  softplus  220  200  0.948978\n",
      "60  60  softplus  230  200  0.960039\n",
      "61  61  softplus  240  200  0.949950\n",
      "62  62  softplus  250  200  0.951561\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  210  0.936049\n",
      "1    1      relu   60  210  0.932027\n",
      "2    2      relu   70  210  0.940247\n",
      "3    3      relu   80  210  0.939094\n",
      "4    4      relu   90  210  0.945145\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  210  0.947348\n",
      "59  59  softplus  220  210  0.950230\n",
      "60  60  softplus  230  210  0.948200\n",
      "61  61  softplus  240  210  0.950935\n",
      "62  62  softplus  250  210  0.949395\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  220  0.927798\n",
      "1    1      relu   60  220  0.932337\n",
      "2    2      relu   70  220  0.945849\n",
      "3    3      relu   80  220  0.951521\n",
      "4    4      relu   90  220  0.936315\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  220  0.947558\n",
      "59  59  softplus  220  220  0.946665\n",
      "60  60  softplus  230  220  0.947564\n",
      "61  61  softplus  240  220  0.947640\n",
      "62  62  softplus  250  220  0.950189\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  230  0.930882\n",
      "1    1      relu   60  230  0.946638\n",
      "2    2      relu   70  230  0.947370\n",
      "3    3      relu   80  230  0.950035\n",
      "4    4      relu   90  230  0.949602\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  230  0.950761\n",
      "59  59  softplus  220  230  0.950960\n",
      "60  60  softplus  230  230  0.949182\n",
      "61  61  softplus  240  230  0.960086\n",
      "62  62  softplus  250  230  0.949688\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2   3         4\n",
      "0    0      relu   50  60  0.883578\n",
      "1    1      relu   60  60  0.884147\n",
      "2    2      relu   70  60  0.900938\n",
      "3    3      relu   80  60  0.900286\n",
      "4    4      relu   90  60  0.906729\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  60  0.930259\n",
      "59  59  softplus  220  60  0.927486\n",
      "60  60  softplus  230  60  0.926990\n",
      "61  61  softplus  240  60  0.928506\n",
      "62  62  softplus  250  60  0.931282\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  240  0.940044\n",
      "1    1      relu   60  240  0.941955\n",
      "2    2      relu   70  240  0.955216\n",
      "3    3      relu   80  240  0.954642\n",
      "4    4      relu   90  240  0.946582\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  240  0.948614\n",
      "59  59  softplus  220  240  0.949042\n",
      "60  60  softplus  230  240  0.949593\n",
      "61  61  softplus  240  240  0.950349\n",
      "62  62  softplus  250  240  0.950513\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  250  0.931790\n",
      "1    1      relu   60  250  0.947392\n",
      "2    2      relu   70  250  0.944336\n",
      "3    3      relu   80  250  0.954378\n",
      "4    4      relu   90  250  0.952455\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  250  0.949144\n",
      "59  59  softplus  220  250  0.949310\n",
      "60  60  softplus  230  250  0.950075\n",
      "61  61  softplus  240  250  0.950537\n",
      "62  62  softplus  250  250  0.953523\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2   3         4\n",
      "0    0      relu   50  70  0.892649\n",
      "1    1      relu   60  70  0.906550\n",
      "2    2      relu   70  70  0.902013\n",
      "3    3      relu   80  70  0.905800\n",
      "4    4      relu   90  70  0.909428\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  70  0.930192\n",
      "59  59  softplus  220  70  0.929728\n",
      "60  60  softplus  230  70  0.927943\n",
      "61  61  softplus  240  70  0.935008\n",
      "62  62  softplus  250  70  0.935967\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2   3         4\n",
      "0    0      relu   50  80  0.910040\n",
      "1    1      relu   60  80  0.904055\n",
      "2    2      relu   70  80  0.908620\n",
      "3    3      relu   80  80  0.904928\n",
      "4    4      relu   90  80  0.912573\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  80  0.929256\n",
      "59  59  softplus  220  80  0.935120\n",
      "60  60  softplus  230  80  0.929965\n",
      "61  61  softplus  240  80  0.933534\n",
      "62  62  softplus  250  80  0.932175\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2   3         4\n",
      "0    0      relu   50  90  0.909586\n",
      "1    1      relu   60  90  0.899804\n",
      "2    2      relu   70  90  0.920348\n",
      "3    3      relu   80  90  0.909628\n",
      "4    4      relu   90  90  0.921137\n",
      "..  ..       ...  ...  ..       ...\n",
      "58  58  softplus  210  90  0.934289\n",
      "59  59  softplus  220  90  0.930752\n",
      "60  60  softplus  230  90  0.931668\n",
      "61  61  softplus  240  90  0.937478\n",
      "62  62  softplus  250  90  0.932534\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  100  0.911371\n",
      "1    1      relu   60  100  0.920362\n",
      "2    2      relu   70  100  0.915463\n",
      "3    3      relu   80  100  0.922894\n",
      "4    4      relu   90  100  0.920317\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  100  0.936263\n",
      "59  59  softplus  220  100  0.934567\n",
      "60  60  softplus  230  100  0.938219\n",
      "61  61  softplus  240  100  0.936610\n",
      "62  62  softplus  250  100  0.937632\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  110  0.916712\n",
      "1    1      relu   60  110  0.921577\n",
      "2    2      relu   70  110  0.904278\n",
      "3    3      relu   80  110  0.925631\n",
      "4    4      relu   90  110  0.919107\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  110  0.953950\n",
      "59  59  softplus  220  110  0.942228\n",
      "60  60  softplus  230  110  0.942113\n",
      "61  61  softplus  240  110  0.940579\n",
      "62  62  softplus  250  110  0.943773\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  120  0.918640\n",
      "1    1      relu   60  120  0.915531\n",
      "2    2      relu   70  120  0.921513\n",
      "3    3      relu   80  120  0.917383\n",
      "4    4      relu   90  120  0.923036\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  120  0.937042\n",
      "59  59  softplus  220  120  0.940869\n",
      "60  60  softplus  230  120  0.954155\n",
      "61  61  softplus  240  120  0.956678\n",
      "62  62  softplus  250  120  0.944686\n",
      "\n",
      "[63 rows x 5 columns],      0         1    2    3         4\n",
      "0    0      relu   50  130  0.923570\n",
      "1    1      relu   60  130  0.916895\n",
      "2    2      relu   70  130  0.920807\n",
      "3    3      relu   80  130  0.921505\n",
      "4    4      relu   90  130  0.929538\n",
      "..  ..       ...  ...  ...       ...\n",
      "58  58  softplus  210  130  0.952788\n",
      "59  59  softplus  220  130  0.936866\n",
      "60  60  softplus  230  130  0.953930\n",
      "61  61  softplus  240  130  0.944769\n",
      "62  62  softplus  250  130  0.964354\n",
      "\n",
      "[63 rows x 5 columns]]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "redirect_dir = current_dir.parent.parent.parent\n",
    "\n",
    "#Access input folder\n",
    "input_dir = Path (redirect_dir/\"1D_Tracers/Hyperparameter tuning summary_ANN/Reflected_pressure_hyperparameter_tuning2\")\n",
    "print (\"1\",input_dir)\n",
    "\n",
    "# Output Excel file\n",
    "output_excel_file = Path(input_dir/\"S1_summary.xlsx\")\n",
    "\n",
    "# List to store DataFrames from CSV files\n",
    "dfs = []\n",
    "\n",
    "# Loop through CSV files in the directory\n",
    "for csv_file in input_dir.glob('*.csv'):\n",
    "    # Read CSV file into a DataFrame and append to the list\n",
    "    df = pd.read_csv(csv_file, header = None)\n",
    "    dfs.append(df)\n",
    "\n",
    "print (dfs)\n",
    "\n",
    "# Concatenate DataFrames in the list along rows\n",
    "merged_df = pd.concat(dfs, axis = 0,ignore_index=False)\n",
    "\n",
    "# Write the merged DataFrame to an Excel file\n",
    "merged_df.to_excel(output_excel_file, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T03:33:50.352467600Z",
     "start_time": "2024-02-06T03:33:50.087498400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### S2 - Hyperparameter tuning - batch size, epoch, optimizer, learning rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Nadam\n",
    "# Set seed for NumPy\n",
    "np.random.seed(54)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(54)\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model2():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=240, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=190, activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    " return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T03:35:39.473414200Z",
     "start_time": "2024-02-06T03:35:39.449891400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.996012 using {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.939661 (0.045601) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.989652 (0.010449) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.986814 (0.009287) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.303029 (0.395239) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 1}\n",
      "0.037679 (0.092810) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 2}\n",
      "0.942037 (0.040403) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.988816 (0.008227) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.976378 (0.030581) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.289791 (0.392732) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 1}\n",
      "-0.016463 (0.019590) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 2}\n",
      "0.930284 (0.053268) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.988473 (0.013654) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.986961 (0.007756) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.682584 (0.351230) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 1}\n",
      "-0.016089 (0.015938) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 2}\n",
      "0.914514 (0.070440) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.994000 (0.006766) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.980743 (0.027188) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "-0.014689 (0.013981) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 1}\n",
      "-0.017175 (0.018877) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 2}\n",
      "0.917160 (0.064675) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.992055 (0.011738) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.996012 (0.001747) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "-0.016746 (0.017777) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 1}\n",
      "-0.018386 (0.021579) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 2}\n",
      "0.910714 (0.069305) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.981219 (0.022321) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.995661 (0.002168) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.722799 (0.365393) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 1}\n",
      "-0.025223 (0.036224) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 2}\n",
      "0.909737 (0.072415) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.993932 (0.006497) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.987187 (0.014673) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.314249 (0.401021) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 1}\n",
      "-0.017286 (0.019201) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 2}\n",
      "0.909685 (0.076130) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.994364 (0.006825) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.989625 (0.006784) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.494138 (0.414608) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 1}\n",
      "0.160252 (0.357177) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 2}\n",
      "0.895375 (0.090343) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.987374 (0.010757) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.992771 (0.003869) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.698347 (0.360934) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 1}\n",
      "0.004334 (0.058111) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 2}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model2 = KerasRegressor(model=create_model2, verbose=0, random_state = 54, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [30,40,50]\n",
    "optimizer = [Adam, Nadam, RMSprop]\n",
    "learning_rate = [ 0.001,0.01, 0.1, 1, 2]\n",
    "epochs = [500]\n",
    "\n",
    "# gridsearch\n",
    "param_grid2 = dict(batch_size=batch_size, optimizer=optimizer, optimizer__learning_rate = learning_rate, epochs = epochs)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=54)\n",
    "grid2 = GridSearchCV(estimator=model2, param_grid=param_grid2, n_jobs=-1, scoring = 'r2', cv=kf)\n",
    "grid_result2 = grid2.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T03:39:41.282410Z",
     "start_time": "2024-02-06T03:36:20.360981900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "    batch_size  epochs                                       optimizer  \\\n0           30     500        <class 'keras.src.optimizers.adam.Adam'>   \n1           30     500        <class 'keras.src.optimizers.adam.Adam'>   \n2           30     500        <class 'keras.src.optimizers.adam.Adam'>   \n3           30     500        <class 'keras.src.optimizers.adam.Adam'>   \n4           30     500        <class 'keras.src.optimizers.adam.Adam'>   \n5           30     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n6           30     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n7           30     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n8           30     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n9           30     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n10          30     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n11          30     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n12          30     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n13          30     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n14          30     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n15          40     500        <class 'keras.src.optimizers.adam.Adam'>   \n16          40     500        <class 'keras.src.optimizers.adam.Adam'>   \n17          40     500        <class 'keras.src.optimizers.adam.Adam'>   \n18          40     500        <class 'keras.src.optimizers.adam.Adam'>   \n19          40     500        <class 'keras.src.optimizers.adam.Adam'>   \n20          40     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n21          40     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n22          40     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n23          40     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n24          40     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n25          40     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n26          40     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n27          40     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n28          40     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n29          40     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n30          50     500        <class 'keras.src.optimizers.adam.Adam'>   \n31          50     500        <class 'keras.src.optimizers.adam.Adam'>   \n32          50     500        <class 'keras.src.optimizers.adam.Adam'>   \n33          50     500        <class 'keras.src.optimizers.adam.Adam'>   \n34          50     500        <class 'keras.src.optimizers.adam.Adam'>   \n35          50     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n36          50     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n37          50     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n38          50     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n39          50     500      <class 'keras.src.optimizers.nadam.Nadam'>   \n40          50     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n41          50     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n42          50     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n43          50     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n44          50     500  <class 'keras.src.optimizers.rmsprop.RMSprop'>   \n\n    optimizer__learning_rate        R2  \n0                      0.001  0.939661  \n1                      0.010  0.989652  \n2                      0.100  0.986814  \n3                      1.000  0.303029  \n4                      2.000  0.037679  \n5                      0.001  0.942037  \n6                      0.010  0.988816  \n7                      0.100  0.976378  \n8                      1.000  0.289791  \n9                      2.000 -0.016463  \n10                     0.001  0.930284  \n11                     0.010  0.988473  \n12                     0.100  0.986961  \n13                     1.000  0.682584  \n14                     2.000 -0.016089  \n15                     0.001  0.914514  \n16                     0.010  0.994000  \n17                     0.100  0.980743  \n18                     1.000 -0.014689  \n19                     2.000 -0.017175  \n20                     0.001  0.917160  \n21                     0.010  0.992055  \n22                     0.100  0.996012  \n23                     1.000 -0.016746  \n24                     2.000 -0.018386  \n25                     0.001  0.910714  \n26                     0.010  0.981219  \n27                     0.100  0.995661  \n28                     1.000  0.722799  \n29                     2.000 -0.025223  \n30                     0.001  0.909737  \n31                     0.010  0.993932  \n32                     0.100  0.987187  \n33                     1.000  0.314249  \n34                     2.000 -0.017286  \n35                     0.001  0.909685  \n36                     0.010  0.994364  \n37                     0.100  0.989625  \n38                     1.000  0.494138  \n39                     2.000  0.160252  \n40                     0.001  0.895375  \n41                     0.010  0.987374  \n42                     0.100  0.992771  \n43                     1.000  0.698347  \n44                     2.000  0.004334  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>batch_size</th>\n      <th>epochs</th>\n      <th>optimizer</th>\n      <th>optimizer__learning_rate</th>\n      <th>R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.001</td>\n      <td>0.939661</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.010</td>\n      <td>0.989652</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.100</td>\n      <td>0.986814</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>1.000</td>\n      <td>0.303029</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>2.000</td>\n      <td>0.037679</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.001</td>\n      <td>0.942037</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.010</td>\n      <td>0.988816</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.100</td>\n      <td>0.976378</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>1.000</td>\n      <td>0.289791</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>2.000</td>\n      <td>-0.016463</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.001</td>\n      <td>0.930284</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.010</td>\n      <td>0.988473</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.100</td>\n      <td>0.986961</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>1.000</td>\n      <td>0.682584</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>30</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>2.000</td>\n      <td>-0.016089</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.001</td>\n      <td>0.914514</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.010</td>\n      <td>0.994000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.100</td>\n      <td>0.980743</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>1.000</td>\n      <td>-0.014689</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>2.000</td>\n      <td>-0.017175</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.001</td>\n      <td>0.917160</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.010</td>\n      <td>0.992055</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.100</td>\n      <td>0.996012</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>1.000</td>\n      <td>-0.016746</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>2.000</td>\n      <td>-0.018386</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.001</td>\n      <td>0.910714</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.010</td>\n      <td>0.981219</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.100</td>\n      <td>0.995661</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>1.000</td>\n      <td>0.722799</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>40</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>2.000</td>\n      <td>-0.025223</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.001</td>\n      <td>0.909737</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.010</td>\n      <td>0.993932</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>0.100</td>\n      <td>0.987187</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>1.000</td>\n      <td>0.314249</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.adam.Adam'&gt;</td>\n      <td>2.000</td>\n      <td>-0.017286</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.001</td>\n      <td>0.909685</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.010</td>\n      <td>0.994364</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>0.100</td>\n      <td>0.989625</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>1.000</td>\n      <td>0.494138</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.nadam.Nadam'&gt;</td>\n      <td>2.000</td>\n      <td>0.160252</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.001</td>\n      <td>0.895375</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.010</td>\n      <td>0.987374</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>0.100</td>\n      <td>0.992771</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>1.000</td>\n      <td>0.698347</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>50</td>\n      <td>500</td>\n      <td>&lt;class 'keras.src.optimizers.rmsprop.RMSprop'&gt;</td>\n      <td>2.000</td>\n      <td>0.004334</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(params), pd.DataFrame(means, columns=['R2'])], axis =1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T03:42:45.717179200Z",
     "start_time": "2024-02-06T03:42:45.686425500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_result2.best_params_\n",
    "print (best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T03:44:32.708571600Z",
     "start_time": "2024-02-06T03:44:32.677884900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# Create the final model using the best hyperparameters\n",
    "final_model = KerasRegressor(\n",
    "    build_fn=create_model2,\n",
    "    verbose=0,\n",
    "    random_state=71,\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae'],\n",
    "    optimizer = Adam,\n",
    "    optimizer__learning_rate = 0.1\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T22:19:37.637949900Z",
     "start_time": "2024-02-05T22:19:37.610683800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 44ms/step - loss: 55832392.0000 - mean_absolute_error: 3198.1384 - val_loss: 61575016.0000 - val_mean_absolute_error: 2673.4590\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 42599968.0000 - mean_absolute_error: 2141.0654 - val_loss: 36317188.0000 - val_mean_absolute_error: 3169.7666\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 27840188.0000 - mean_absolute_error: 1876.9525 - val_loss: 20953434.0000 - val_mean_absolute_error: 1656.2485\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 17600802.0000 - mean_absolute_error: 1265.4921 - val_loss: 12577524.0000 - val_mean_absolute_error: 1069.9705\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 8313207.0000 - mean_absolute_error: 792.6152 - val_loss: 8627887.0000 - val_mean_absolute_error: 1009.2715\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 4699439.0000 - mean_absolute_error: 633.5383 - val_loss: 7263181.0000 - val_mean_absolute_error: 811.1264\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 5971058.0000 - mean_absolute_error: 680.4688 - val_loss: 23177994.0000 - val_mean_absolute_error: 1689.3185\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 8886232.0000 - mean_absolute_error: 771.5047 - val_loss: 8841786.0000 - val_mean_absolute_error: 1060.4414\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 5914023.0000 - mean_absolute_error: 660.8378 - val_loss: 3955311.7500 - val_mean_absolute_error: 617.3561\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 8456074.0000 - mean_absolute_error: 772.2906 - val_loss: 30504990.0000 - val_mean_absolute_error: 1893.9113\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 24546134.0000 - mean_absolute_error: 1411.5204 - val_loss: 5234631.5000 - val_mean_absolute_error: 735.6415\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 45973608.0000 - mean_absolute_error: 1700.7743 - val_loss: 61294916.0000 - val_mean_absolute_error: 2718.2944\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 45176188.0000 - mean_absolute_error: 1806.2792 - val_loss: 20442136.0000 - val_mean_absolute_error: 2037.7516\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 18505018.0000 - mean_absolute_error: 1636.1229 - val_loss: 8141271.5000 - val_mean_absolute_error: 989.1035\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 10073555.0000 - mean_absolute_error: 904.9071 - val_loss: 4962600.0000 - val_mean_absolute_error: 804.8017\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 10419343.0000 - mean_absolute_error: 913.6617 - val_loss: 40483928.0000 - val_mean_absolute_error: 2382.3760\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 15320140.0000 - mean_absolute_error: 1097.2604 - val_loss: 13578394.0000 - val_mean_absolute_error: 1138.5200\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 6809830.0000 - mean_absolute_error: 745.2371 - val_loss: 3534398.5000 - val_mean_absolute_error: 655.0246\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 7099259.5000 - mean_absolute_error: 739.9714 - val_loss: 12769041.0000 - val_mean_absolute_error: 1272.4960\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 6603988.0000 - mean_absolute_error: 745.7128 - val_loss: 5109988.0000 - val_mean_absolute_error: 673.4233\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 12781791.0000 - mean_absolute_error: 941.1814 - val_loss: 19230446.0000 - val_mean_absolute_error: 1593.1859\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 4807604.5000 - mean_absolute_error: 672.2284 - val_loss: 9143805.0000 - val_mean_absolute_error: 1080.4425\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 5634499.0000 - mean_absolute_error: 648.5107 - val_loss: 3854945.5000 - val_mean_absolute_error: 680.4368\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2780442.2500 - mean_absolute_error: 488.7492 - val_loss: 1980392.0000 - val_mean_absolute_error: 531.3167\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 4146971.0000 - mean_absolute_error: 575.6279 - val_loss: 19487078.0000 - val_mean_absolute_error: 1589.1122\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 4383359.5000 - mean_absolute_error: 625.2576 - val_loss: 1773086.5000 - val_mean_absolute_error: 501.5331\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 4214840.5000 - mean_absolute_error: 499.0333 - val_loss: 2057642.8750 - val_mean_absolute_error: 458.3056\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 7545821.0000 - mean_absolute_error: 654.8577 - val_loss: 7065350.0000 - val_mean_absolute_error: 970.8735\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 7161584.0000 - mean_absolute_error: 679.0518 - val_loss: 21467488.0000 - val_mean_absolute_error: 1617.7507\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 8919246.0000 - mean_absolute_error: 872.0140 - val_loss: 15896119.0000 - val_mean_absolute_error: 1414.5087\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 8623424.0000 - mean_absolute_error: 694.3783 - val_loss: 8499193.0000 - val_mean_absolute_error: 850.4719\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3053478.2500 - mean_absolute_error: 509.3716 - val_loss: 2089262.5000 - val_mean_absolute_error: 500.2027\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 3055280.2500 - mean_absolute_error: 441.5067 - val_loss: 1472328.8750 - val_mean_absolute_error: 408.2193\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2696025.5000 - mean_absolute_error: 436.4921 - val_loss: 1126338.8750 - val_mean_absolute_error: 365.2026\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3006400.7500 - mean_absolute_error: 479.1826 - val_loss: 8843206.0000 - val_mean_absolute_error: 1042.0751\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2366686.7500 - mean_absolute_error: 435.9611 - val_loss: 6028523.0000 - val_mean_absolute_error: 841.1572\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 4248228.5000 - mean_absolute_error: 560.4564 - val_loss: 2800573.7500 - val_mean_absolute_error: 573.2241\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1225492.7500 - mean_absolute_error: 331.6683 - val_loss: 1704335.2500 - val_mean_absolute_error: 430.1806\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1103907.2500 - mean_absolute_error: 297.1871 - val_loss: 1148504.6250 - val_mean_absolute_error: 391.0829\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1835509.1250 - mean_absolute_error: 373.3425 - val_loss: 1977922.1250 - val_mean_absolute_error: 485.7695\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1441583.1250 - mean_absolute_error: 351.5538 - val_loss: 1341030.3750 - val_mean_absolute_error: 403.1495\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 749625.3125 - mean_absolute_error: 287.8500 - val_loss: 2874857.0000 - val_mean_absolute_error: 543.4080\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1498160.6250 - mean_absolute_error: 331.0364 - val_loss: 1585159.2500 - val_mean_absolute_error: 407.7475\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 4062726.7500 - mean_absolute_error: 526.0372 - val_loss: 871064.5625 - val_mean_absolute_error: 349.3516\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1386717.6250 - mean_absolute_error: 327.8968 - val_loss: 647818.0000 - val_mean_absolute_error: 338.2379\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1510342.8750 - mean_absolute_error: 369.2622 - val_loss: 611631.2500 - val_mean_absolute_error: 268.0326\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2885235.7500 - mean_absolute_error: 499.8278 - val_loss: 842245.8125 - val_mean_absolute_error: 313.3831\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 700411.1875 - mean_absolute_error: 274.1561 - val_loss: 1045855.1875 - val_mean_absolute_error: 389.0160\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 462634.5000 - mean_absolute_error: 255.8260 - val_loss: 867459.2500 - val_mean_absolute_error: 362.2180\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 754461.0625 - mean_absolute_error: 283.2124 - val_loss: 2014706.0000 - val_mean_absolute_error: 512.2598\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 576103.8750 - mean_absolute_error: 267.2690 - val_loss: 616863.0625 - val_mean_absolute_error: 293.4509\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 428977.5938 - mean_absolute_error: 230.5561 - val_loss: 562861.5000 - val_mean_absolute_error: 281.4472\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 532290.5000 - mean_absolute_error: 259.0878 - val_loss: 802577.8125 - val_mean_absolute_error: 317.0082\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 687736.7500 - mean_absolute_error: 269.0916 - val_loss: 4092602.2500 - val_mean_absolute_error: 672.0541\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2615337.7500 - mean_absolute_error: 415.1841 - val_loss: 1058677.5000 - val_mean_absolute_error: 335.9287\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2864318.2500 - mean_absolute_error: 419.4170 - val_loss: 1288696.8750 - val_mean_absolute_error: 408.2648\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1082192.0000 - mean_absolute_error: 319.6197 - val_loss: 639325.7500 - val_mean_absolute_error: 313.6840\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 394187.7500 - mean_absolute_error: 248.3335 - val_loss: 850567.4375 - val_mean_absolute_error: 375.9177\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 401293.3125 - mean_absolute_error: 249.2604 - val_loss: 531060.4375 - val_mean_absolute_error: 279.6821\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 316044.7812 - mean_absolute_error: 200.5340 - val_loss: 503493.8125 - val_mean_absolute_error: 268.8392\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 268409.1562 - mean_absolute_error: 192.3305 - val_loss: 861798.8125 - val_mean_absolute_error: 308.5957\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 257318.6719 - mean_absolute_error: 178.8233 - val_loss: 491809.2188 - val_mean_absolute_error: 285.3482\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 267693.0312 - mean_absolute_error: 177.0850 - val_loss: 465254.0000 - val_mean_absolute_error: 259.4689\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 284474.2812 - mean_absolute_error: 191.9109 - val_loss: 476765.1250 - val_mean_absolute_error: 254.8501\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 196341.8125 - mean_absolute_error: 173.8691 - val_loss: 773466.0000 - val_mean_absolute_error: 299.0404\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 344469.0312 - mean_absolute_error: 195.9561 - val_loss: 962890.0625 - val_mean_absolute_error: 321.1608\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 377050.1875 - mean_absolute_error: 205.2754 - val_loss: 1095501.1250 - val_mean_absolute_error: 357.2622\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 288241.1562 - mean_absolute_error: 193.7963 - val_loss: 440810.7188 - val_mean_absolute_error: 261.1203\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 167244.8125 - mean_absolute_error: 148.2376 - val_loss: 386480.2188 - val_mean_absolute_error: 269.6085\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 170544.1719 - mean_absolute_error: 168.4000 - val_loss: 411028.4688 - val_mean_absolute_error: 260.3155\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 195536.5625 - mean_absolute_error: 165.6479 - val_loss: 597226.8750 - val_mean_absolute_error: 267.0054\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 206401.7188 - mean_absolute_error: 175.8000 - val_loss: 454658.1250 - val_mean_absolute_error: 241.7229\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 129815.9219 - mean_absolute_error: 149.9258 - val_loss: 258869.4062 - val_mean_absolute_error: 223.3450\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 285365.7188 - mean_absolute_error: 179.8832 - val_loss: 499924.5938 - val_mean_absolute_error: 308.2658\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 356538.9062 - mean_absolute_error: 197.0697 - val_loss: 351239.0312 - val_mean_absolute_error: 205.2535\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 288817.1875 - mean_absolute_error: 179.1235 - val_loss: 1101480.5000 - val_mean_absolute_error: 380.0365\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 207652.0938 - mean_absolute_error: 183.0456 - val_loss: 1015932.3750 - val_mean_absolute_error: 430.2101\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 797644.5625 - mean_absolute_error: 288.1151 - val_loss: 395394.5312 - val_mean_absolute_error: 236.1393\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 309734.8438 - mean_absolute_error: 189.0296 - val_loss: 370565.8750 - val_mean_absolute_error: 251.6424\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 805230.8125 - mean_absolute_error: 256.3985 - val_loss: 619479.8125 - val_mean_absolute_error: 260.1158\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 153275.0469 - mean_absolute_error: 159.9132 - val_loss: 452535.6875 - val_mean_absolute_error: 222.6825\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 283785.9062 - mean_absolute_error: 181.9069 - val_loss: 409693.5312 - val_mean_absolute_error: 217.7813\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 226751.0469 - mean_absolute_error: 176.4180 - val_loss: 397587.1875 - val_mean_absolute_error: 276.7590\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 303981.7500 - mean_absolute_error: 179.5541 - val_loss: 397156.2188 - val_mean_absolute_error: 270.1518\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 363197.6562 - mean_absolute_error: 197.2486 - val_loss: 209099.3125 - val_mean_absolute_error: 194.0941\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 469630.5625 - mean_absolute_error: 203.2402 - val_loss: 387016.0000 - val_mean_absolute_error: 238.2318\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 186382.1250 - mean_absolute_error: 161.6200 - val_loss: 298370.2500 - val_mean_absolute_error: 216.1266\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 77709.1328 - mean_absolute_error: 121.9443 - val_loss: 317358.2188 - val_mean_absolute_error: 198.5987\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 121523.2344 - mean_absolute_error: 138.6851 - val_loss: 251990.7656 - val_mean_absolute_error: 215.7457\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 147844.2188 - mean_absolute_error: 137.1871 - val_loss: 307721.9375 - val_mean_absolute_error: 188.6390\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 100781.3047 - mean_absolute_error: 134.2170 - val_loss: 411777.4688 - val_mean_absolute_error: 213.2434\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 113731.0781 - mean_absolute_error: 141.6092 - val_loss: 495838.4688 - val_mean_absolute_error: 249.0647\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 174019.5625 - mean_absolute_error: 156.9419 - val_loss: 659525.0000 - val_mean_absolute_error: 270.7621\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 101753.0156 - mean_absolute_error: 141.3969 - val_loss: 450531.4062 - val_mean_absolute_error: 215.4916\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 509507.5312 - mean_absolute_error: 190.7586 - val_loss: 306033.8750 - val_mean_absolute_error: 257.1774\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 770373.7500 - mean_absolute_error: 276.7740 - val_loss: 458815.6250 - val_mean_absolute_error: 242.1542\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 342695.1562 - mean_absolute_error: 187.7829 - val_loss: 335250.1250 - val_mean_absolute_error: 257.6843\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 430783.0000 - mean_absolute_error: 234.0570 - val_loss: 826998.4375 - val_mean_absolute_error: 382.2780\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2263307.7500 - mean_absolute_error: 491.9949 - val_loss: 4771710.5000 - val_mean_absolute_error: 877.3986\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1307827.8750 - mean_absolute_error: 421.2968 - val_loss: 2254609.7500 - val_mean_absolute_error: 579.5356\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 2149520.0000 - mean_absolute_error: 434.4877 - val_loss: 3249950.5000 - val_mean_absolute_error: 711.7736\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1367379.7500 - mean_absolute_error: 367.6468 - val_loss: 3174710.2500 - val_mean_absolute_error: 583.1963\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1806386.6250 - mean_absolute_error: 413.5836 - val_loss: 6097451.5000 - val_mean_absolute_error: 896.5737\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1115040.3750 - mean_absolute_error: 294.4550 - val_loss: 1716916.0000 - val_mean_absolute_error: 435.9655\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1543908.1250 - mean_absolute_error: 348.1726 - val_loss: 1797252.8750 - val_mean_absolute_error: 489.8972\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3828468.7500 - mean_absolute_error: 590.8862 - val_loss: 3994033.5000 - val_mean_absolute_error: 634.6146\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2307028.7500 - mean_absolute_error: 479.9833 - val_loss: 1746703.8750 - val_mean_absolute_error: 501.5695\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1594493.6250 - mean_absolute_error: 412.6413 - val_loss: 9053495.0000 - val_mean_absolute_error: 1060.7511\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3747717.0000 - mean_absolute_error: 567.4088 - val_loss: 3978726.5000 - val_mean_absolute_error: 731.3728\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3193905.2500 - mean_absolute_error: 510.8344 - val_loss: 3454204.0000 - val_mean_absolute_error: 630.6085\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2160294.0000 - mean_absolute_error: 467.6839 - val_loss: 556190.4375 - val_mean_absolute_error: 310.2344\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1976950.0000 - mean_absolute_error: 413.5375 - val_loss: 1308797.2500 - val_mean_absolute_error: 474.1537\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 6603693.0000 - mean_absolute_error: 736.8784 - val_loss: 17111558.0000 - val_mean_absolute_error: 1756.7098\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 6066966.5000 - mean_absolute_error: 758.6100 - val_loss: 4173024.0000 - val_mean_absolute_error: 646.2006\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1672915.1250 - mean_absolute_error: 376.0341 - val_loss: 2560601.0000 - val_mean_absolute_error: 515.6045\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1429844.7500 - mean_absolute_error: 370.0564 - val_loss: 1217098.7500 - val_mean_absolute_error: 368.8182\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 683970.1250 - mean_absolute_error: 279.4704 - val_loss: 1463279.1250 - val_mean_absolute_error: 392.6729\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 578250.3750 - mean_absolute_error: 234.7022 - val_loss: 1003672.4375 - val_mean_absolute_error: 342.6011\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 503199.0625 - mean_absolute_error: 221.9500 - val_loss: 772625.1875 - val_mean_absolute_error: 284.4258\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 309729.1562 - mean_absolute_error: 179.8051 - val_loss: 723137.4375 - val_mean_absolute_error: 304.2691\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1481991.3750 - mean_absolute_error: 350.7307 - val_loss: 989335.3750 - val_mean_absolute_error: 338.5461\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 295337.3750 - mean_absolute_error: 186.8623 - val_loss: 623938.8125 - val_mean_absolute_error: 249.5079\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 311471.7812 - mean_absolute_error: 175.4877 - val_loss: 286333.0938 - val_mean_absolute_error: 211.8454\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 99301.6094 - mean_absolute_error: 127.2539 - val_loss: 216303.9531 - val_mean_absolute_error: 189.9502\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 143745.5625 - mean_absolute_error: 143.8798 - val_loss: 453348.0938 - val_mean_absolute_error: 231.7056\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 91752.2734 - mean_absolute_error: 126.8162 - val_loss: 246126.9844 - val_mean_absolute_error: 197.2476\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 64909.9336 - mean_absolute_error: 113.9240 - val_loss: 293052.3750 - val_mean_absolute_error: 181.1962\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 198836.0469 - mean_absolute_error: 159.7614 - val_loss: 204752.0469 - val_mean_absolute_error: 172.3887\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 128056.2812 - mean_absolute_error: 144.9463 - val_loss: 707943.7500 - val_mean_absolute_error: 284.1147\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 138769.3438 - mean_absolute_error: 142.9869 - val_loss: 384145.0000 - val_mean_absolute_error: 211.7446\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 59742.8477 - mean_absolute_error: 115.1577 - val_loss: 247661.6562 - val_mean_absolute_error: 180.1632\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 52774.3164 - mean_absolute_error: 111.1438 - val_loss: 285278.9688 - val_mean_absolute_error: 164.5377\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 55822.4375 - mean_absolute_error: 109.3000 - val_loss: 373491.8125 - val_mean_absolute_error: 204.2748\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 47085.1484 - mean_absolute_error: 103.2791 - val_loss: 650435.5625 - val_mean_absolute_error: 260.7346\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 99241.3125 - mean_absolute_error: 123.9478 - val_loss: 472081.0000 - val_mean_absolute_error: 210.8125\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 51649.9570 - mean_absolute_error: 99.6987 - val_loss: 247560.7344 - val_mean_absolute_error: 178.6242\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 61531.9609 - mean_absolute_error: 111.1917 - val_loss: 258341.2500 - val_mean_absolute_error: 208.7112\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 94481.4766 - mean_absolute_error: 134.0845 - val_loss: 263991.8438 - val_mean_absolute_error: 207.7002\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 123711.8906 - mean_absolute_error: 139.0866 - val_loss: 322546.9062 - val_mean_absolute_error: 183.0296\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 633014.2500 - mean_absolute_error: 221.3315 - val_loss: 395145.6250 - val_mean_absolute_error: 191.2842\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 282356.6250 - mean_absolute_error: 183.2344 - val_loss: 4587579.5000 - val_mean_absolute_error: 681.4666\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1927015.8750 - mean_absolute_error: 370.2418 - val_loss: 4816560.5000 - val_mean_absolute_error: 738.6288\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 8119341.5000 - mean_absolute_error: 769.7352 - val_loss: 9323969.0000 - val_mean_absolute_error: 1122.0858\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 7332527.0000 - mean_absolute_error: 684.3890 - val_loss: 5696456.0000 - val_mean_absolute_error: 883.3510\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 5988678.0000 - mean_absolute_error: 659.7073 - val_loss: 16236998.0000 - val_mean_absolute_error: 1265.3901\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3753066.2500 - mean_absolute_error: 561.8805 - val_loss: 1017227.6250 - val_mean_absolute_error: 418.4461\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1081680.0000 - mean_absolute_error: 290.2224 - val_loss: 709286.9375 - val_mean_absolute_error: 330.6281\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1244169.6250 - mean_absolute_error: 316.9613 - val_loss: 5565040.5000 - val_mean_absolute_error: 762.7584\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3189264.2500 - mean_absolute_error: 432.1001 - val_loss: 997437.3750 - val_mean_absolute_error: 331.3195\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 872470.7500 - mean_absolute_error: 263.6587 - val_loss: 2734509.2500 - val_mean_absolute_error: 599.3696\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1752034.1250 - mean_absolute_error: 382.1902 - val_loss: 2243662.0000 - val_mean_absolute_error: 507.8403\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 861847.6875 - mean_absolute_error: 289.4775 - val_loss: 329087.2500 - val_mean_absolute_error: 242.6099\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1060841.0000 - mean_absolute_error: 256.8563 - val_loss: 1573389.1250 - val_mean_absolute_error: 461.6998\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1474266.0000 - mean_absolute_error: 341.9944 - val_loss: 919512.7500 - val_mean_absolute_error: 332.9611\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 261038.7500 - mean_absolute_error: 184.8230 - val_loss: 613228.3750 - val_mean_absolute_error: 267.6293\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 169329.3281 - mean_absolute_error: 165.0956 - val_loss: 231662.1094 - val_mean_absolute_error: 209.5908\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 120132.1562 - mean_absolute_error: 137.7590 - val_loss: 754199.8125 - val_mean_absolute_error: 292.7536\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 144186.2812 - mean_absolute_error: 138.1120 - val_loss: 255427.9531 - val_mean_absolute_error: 206.9002\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 249543.5469 - mean_absolute_error: 161.4387 - val_loss: 435767.5312 - val_mean_absolute_error: 267.3889\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 348347.4375 - mean_absolute_error: 188.3087 - val_loss: 213805.7656 - val_mean_absolute_error: 173.5519\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 450473.6875 - mean_absolute_error: 190.7379 - val_loss: 287891.4688 - val_mean_absolute_error: 162.7215\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 3005331.2500 - mean_absolute_error: 366.9066 - val_loss: 871062.3750 - val_mean_absolute_error: 346.2631\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 8509945.0000 - mean_absolute_error: 639.8661 - val_loss: 3678987.0000 - val_mean_absolute_error: 750.4120\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 5534015.5000 - mean_absolute_error: 728.6444 - val_loss: 9548240.0000 - val_mean_absolute_error: 1194.6855\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 7304478.5000 - mean_absolute_error: 748.7900 - val_loss: 1198703.3750 - val_mean_absolute_error: 409.9076\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2304455.5000 - mean_absolute_error: 443.2294 - val_loss: 5798122.0000 - val_mean_absolute_error: 788.9397\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3544689.7500 - mean_absolute_error: 494.0391 - val_loss: 1791109.5000 - val_mean_absolute_error: 495.7100\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3686759.7500 - mean_absolute_error: 498.0504 - val_loss: 7690777.5000 - val_mean_absolute_error: 1033.4183\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 5219742.5000 - mean_absolute_error: 616.9880 - val_loss: 1582401.1250 - val_mean_absolute_error: 464.4279\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 4816795.0000 - mean_absolute_error: 559.3492 - val_loss: 3237304.0000 - val_mean_absolute_error: 604.3055\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 4489191.0000 - mean_absolute_error: 491.3010 - val_loss: 5635568.5000 - val_mean_absolute_error: 782.7507\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 4525859.5000 - mean_absolute_error: 626.3825 - val_loss: 2161808.0000 - val_mean_absolute_error: 491.0196\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 4370033.5000 - mean_absolute_error: 572.8410 - val_loss: 15340736.0000 - val_mean_absolute_error: 1201.2648\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 6171148.0000 - mean_absolute_error: 653.5556 - val_loss: 2311506.5000 - val_mean_absolute_error: 590.0440\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2620834.2500 - mean_absolute_error: 455.3759 - val_loss: 1388252.3750 - val_mean_absolute_error: 408.5089\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1235390.1250 - mean_absolute_error: 284.8266 - val_loss: 2486909.5000 - val_mean_absolute_error: 503.4301\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1991858.6250 - mean_absolute_error: 369.1821 - val_loss: 2955360.2500 - val_mean_absolute_error: 664.7341\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1192837.8750 - mean_absolute_error: 291.3650 - val_loss: 2265810.2500 - val_mean_absolute_error: 503.4812\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 422400.3750 - mean_absolute_error: 203.7850 - val_loss: 814215.7500 - val_mean_absolute_error: 289.5739\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 328541.2500 - mean_absolute_error: 163.5185 - val_loss: 451796.0938 - val_mean_absolute_error: 278.0383\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 202689.8125 - mean_absolute_error: 151.9315 - val_loss: 649206.1875 - val_mean_absolute_error: 261.1557\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 144952.3438 - mean_absolute_error: 138.3379 - val_loss: 246579.3125 - val_mean_absolute_error: 200.3406\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 207793.9062 - mean_absolute_error: 162.4734 - val_loss: 250974.3438 - val_mean_absolute_error: 193.9570\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1088755.5000 - mean_absolute_error: 277.3317 - val_loss: 9640953.0000 - val_mean_absolute_error: 983.5667\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1594673.6250 - mean_absolute_error: 345.0322 - val_loss: 742790.3125 - val_mean_absolute_error: 338.2967\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 431083.5312 - mean_absolute_error: 197.9085 - val_loss: 947280.0000 - val_mean_absolute_error: 312.2860\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 418440.7500 - mean_absolute_error: 192.9274 - val_loss: 1295585.6250 - val_mean_absolute_error: 363.1091\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 325013.0938 - mean_absolute_error: 182.3787 - val_loss: 733240.0625 - val_mean_absolute_error: 274.2141\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 381588.0938 - mean_absolute_error: 184.5123 - val_loss: 522458.5000 - val_mean_absolute_error: 217.5638\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1538914.6250 - mean_absolute_error: 314.4591 - val_loss: 1956868.3750 - val_mean_absolute_error: 522.5352\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1919638.7500 - mean_absolute_error: 417.5422 - val_loss: 306065.8438 - val_mean_absolute_error: 169.1751\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2817912.7500 - mean_absolute_error: 418.4709 - val_loss: 6223478.0000 - val_mean_absolute_error: 849.8256\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 7596980.0000 - mean_absolute_error: 793.4708 - val_loss: 2647629.0000 - val_mean_absolute_error: 586.7488\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2036455.1250 - mean_absolute_error: 474.2155 - val_loss: 6392145.5000 - val_mean_absolute_error: 925.2056\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3325975.2500 - mean_absolute_error: 510.9172 - val_loss: 3788538.2500 - val_mean_absolute_error: 727.2510\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 840744.8125 - mean_absolute_error: 293.5859 - val_loss: 1502326.3750 - val_mean_absolute_error: 419.2625\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1673336.2500 - mean_absolute_error: 359.2801 - val_loss: 2829134.2500 - val_mean_absolute_error: 661.7231\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2625995.7500 - mean_absolute_error: 480.3214 - val_loss: 5057710.5000 - val_mean_absolute_error: 750.7566\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 737295.5625 - mean_absolute_error: 254.7113 - val_loss: 734758.7500 - val_mean_absolute_error: 280.9079\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 593471.1250 - mean_absolute_error: 230.6948 - val_loss: 1053395.8750 - val_mean_absolute_error: 325.7572\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 818627.4375 - mean_absolute_error: 252.2550 - val_loss: 378952.0938 - val_mean_absolute_error: 250.5979\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 319878.0938 - mean_absolute_error: 181.3172 - val_loss: 432173.5312 - val_mean_absolute_error: 286.6336\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 231483.5781 - mean_absolute_error: 176.9374 - val_loss: 537692.4375 - val_mean_absolute_error: 244.8399\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 188489.7656 - mean_absolute_error: 154.1922 - val_loss: 319473.0938 - val_mean_absolute_error: 223.2198\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 130717.0703 - mean_absolute_error: 131.5986 - val_loss: 444074.4062 - val_mean_absolute_error: 228.3161\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 196486.7188 - mean_absolute_error: 160.6381 - val_loss: 565799.7500 - val_mean_absolute_error: 254.9855\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 599537.3750 - mean_absolute_error: 218.6997 - val_loss: 287333.3750 - val_mean_absolute_error: 215.7635\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 407324.8438 - mean_absolute_error: 177.4350 - val_loss: 262016.3906 - val_mean_absolute_error: 208.2355\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 144714.3125 - mean_absolute_error: 130.8100 - val_loss: 348152.9688 - val_mean_absolute_error: 188.2823\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 74944.9141 - mean_absolute_error: 115.0336 - val_loss: 457515.0938 - val_mean_absolute_error: 229.1097\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 71403.7109 - mean_absolute_error: 115.0818 - val_loss: 315732.2188 - val_mean_absolute_error: 234.0030\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 159896.9375 - mean_absolute_error: 144.4132 - val_loss: 646868.0000 - val_mean_absolute_error: 241.5872\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 110919.0000 - mean_absolute_error: 127.9501 - val_loss: 573619.6875 - val_mean_absolute_error: 231.2480\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 133590.7812 - mean_absolute_error: 132.0552 - val_loss: 267689.5000 - val_mean_absolute_error: 197.9850\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 140445.2500 - mean_absolute_error: 142.8993 - val_loss: 367956.6250 - val_mean_absolute_error: 176.4637\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 64694.4805 - mean_absolute_error: 105.6225 - val_loss: 653076.6250 - val_mean_absolute_error: 239.8676\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 75887.1953 - mean_absolute_error: 107.5482 - val_loss: 543462.5625 - val_mean_absolute_error: 219.3347\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 73163.4297 - mean_absolute_error: 103.4469 - val_loss: 459772.7188 - val_mean_absolute_error: 199.2442\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 34441.3516 - mean_absolute_error: 95.8498 - val_loss: 399192.0938 - val_mean_absolute_error: 181.2011\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 26124.9102 - mean_absolute_error: 83.9590 - val_loss: 430727.0938 - val_mean_absolute_error: 182.6127\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 26033.5703 - mean_absolute_error: 77.6967 - val_loss: 326167.1875 - val_mean_absolute_error: 166.5121\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 33822.2578 - mean_absolute_error: 84.8939 - val_loss: 452768.6875 - val_mean_absolute_error: 184.5105\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 28052.9531 - mean_absolute_error: 73.4622 - val_loss: 303594.3125 - val_mean_absolute_error: 155.2403\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 28106.5742 - mean_absolute_error: 74.9170 - val_loss: 339467.0312 - val_mean_absolute_error: 173.8776\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 26163.8184 - mean_absolute_error: 75.0120 - val_loss: 437863.9062 - val_mean_absolute_error: 176.5923\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 22199.4141 - mean_absolute_error: 70.3987 - val_loss: 341645.5312 - val_mean_absolute_error: 144.1173\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 31739.3301 - mean_absolute_error: 75.5906 - val_loss: 233212.1406 - val_mean_absolute_error: 157.5300\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 51590.5664 - mean_absolute_error: 101.3830 - val_loss: 556674.1250 - val_mean_absolute_error: 213.5593\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 48157.8359 - mean_absolute_error: 105.7591 - val_loss: 505430.5938 - val_mean_absolute_error: 196.0419\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 40349.9922 - mean_absolute_error: 95.5803 - val_loss: 355319.9688 - val_mean_absolute_error: 171.1837\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 32863.2812 - mean_absolute_error: 85.7594 - val_loss: 416519.4062 - val_mean_absolute_error: 185.3139\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 28081.5957 - mean_absolute_error: 79.1664 - val_loss: 378157.7188 - val_mean_absolute_error: 163.5267\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 25925.5215 - mean_absolute_error: 79.0490 - val_loss: 231212.4375 - val_mean_absolute_error: 149.1065\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 39233.4492 - mean_absolute_error: 79.7274 - val_loss: 270857.3750 - val_mean_absolute_error: 152.3917\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 21759.8145 - mean_absolute_error: 69.8878 - val_loss: 429960.7188 - val_mean_absolute_error: 160.7750\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 21343.3203 - mean_absolute_error: 71.4261 - val_loss: 374036.7812 - val_mean_absolute_error: 158.3603\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 16728.6133 - mean_absolute_error: 64.1071 - val_loss: 357567.2812 - val_mean_absolute_error: 152.3966\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 26250.7363 - mean_absolute_error: 68.4989 - val_loss: 361916.3125 - val_mean_absolute_error: 150.9781\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 17595.8691 - mean_absolute_error: 63.2679 - val_loss: 298090.0312 - val_mean_absolute_error: 160.4919\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 42366.3945 - mean_absolute_error: 83.5395 - val_loss: 381218.3125 - val_mean_absolute_error: 160.9758\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 45118.4023 - mean_absolute_error: 85.2663 - val_loss: 542388.8125 - val_mean_absolute_error: 199.0063\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 40295.0156 - mean_absolute_error: 77.8773 - val_loss: 428596.9062 - val_mean_absolute_error: 167.4092\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 29409.5664 - mean_absolute_error: 71.4187 - val_loss: 310618.8750 - val_mean_absolute_error: 152.1419\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 13410.3584 - mean_absolute_error: 57.1549 - val_loss: 391425.6250 - val_mean_absolute_error: 159.2105\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 23520.6211 - mean_absolute_error: 69.3152 - val_loss: 235327.4062 - val_mean_absolute_error: 132.8149\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 29436.7344 - mean_absolute_error: 71.6610 - val_loss: 201637.8438 - val_mean_absolute_error: 156.9868\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 104646.4219 - mean_absolute_error: 106.5528 - val_loss: 397149.1875 - val_mean_absolute_error: 148.6218\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 43856.4414 - mean_absolute_error: 80.0800 - val_loss: 314509.9688 - val_mean_absolute_error: 159.8929\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 133405.6406 - mean_absolute_error: 128.0529 - val_loss: 483761.3125 - val_mean_absolute_error: 207.6565\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 208107.4688 - mean_absolute_error: 154.4617 - val_loss: 967298.4375 - val_mean_absolute_error: 328.9944\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 191249.3438 - mean_absolute_error: 174.5316 - val_loss: 493798.8750 - val_mean_absolute_error: 248.3662\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 148871.5156 - mean_absolute_error: 146.6858 - val_loss: 542210.6250 - val_mean_absolute_error: 275.9918\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 334287.8438 - mean_absolute_error: 192.1674 - val_loss: 267996.0938 - val_mean_absolute_error: 169.7501\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 155711.3750 - mean_absolute_error: 143.0151 - val_loss: 933341.5625 - val_mean_absolute_error: 287.3478\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 75711.0781 - mean_absolute_error: 114.5813 - val_loss: 641009.9375 - val_mean_absolute_error: 231.2869\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 68371.9141 - mean_absolute_error: 104.4573 - val_loss: 208032.5000 - val_mean_absolute_error: 133.6037\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 141746.0000 - mean_absolute_error: 130.9740 - val_loss: 495134.5938 - val_mean_absolute_error: 191.3956\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 158191.0781 - mean_absolute_error: 136.8736 - val_loss: 630302.0625 - val_mean_absolute_error: 278.0254\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 138538.7188 - mean_absolute_error: 142.0808 - val_loss: 775799.3750 - val_mean_absolute_error: 253.6015\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 375272.9688 - mean_absolute_error: 202.5234 - val_loss: 404012.1875 - val_mean_absolute_error: 232.8817\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1155211.6250 - mean_absolute_error: 301.9811 - val_loss: 1014847.4375 - val_mean_absolute_error: 334.5473\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 541915.0000 - mean_absolute_error: 250.1717 - val_loss: 1760862.1250 - val_mean_absolute_error: 400.6316\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 316456.2812 - mean_absolute_error: 186.3359 - val_loss: 505286.4062 - val_mean_absolute_error: 255.4580\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 108227.2031 - mean_absolute_error: 150.2123 - val_loss: 415353.5000 - val_mean_absolute_error: 206.7962\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 42794.2812 - mean_absolute_error: 93.2208 - val_loss: 223925.2656 - val_mean_absolute_error: 155.1339\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 43218.1406 - mean_absolute_error: 89.0830 - val_loss: 354037.2500 - val_mean_absolute_error: 173.1037\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 113174.2500 - mean_absolute_error: 123.2239 - val_loss: 1074160.6250 - val_mean_absolute_error: 317.0489\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 180440.4531 - mean_absolute_error: 150.8190 - val_loss: 464223.7812 - val_mean_absolute_error: 217.2456\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 121690.8438 - mean_absolute_error: 118.3064 - val_loss: 338154.9688 - val_mean_absolute_error: 217.8502\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 192639.1406 - mean_absolute_error: 142.4617 - val_loss: 223652.7969 - val_mean_absolute_error: 137.5351\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 89807.4375 - mean_absolute_error: 114.7411 - val_loss: 293733.1875 - val_mean_absolute_error: 153.3210\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 47242.2148 - mean_absolute_error: 95.5771 - val_loss: 494292.4062 - val_mean_absolute_error: 207.1002\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 196022.3438 - mean_absolute_error: 132.9352 - val_loss: 519698.1250 - val_mean_absolute_error: 202.7810\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 79007.8203 - mean_absolute_error: 110.6921 - val_loss: 614933.5625 - val_mean_absolute_error: 307.3649\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 334572.3438 - mean_absolute_error: 169.9563 - val_loss: 222350.0469 - val_mean_absolute_error: 161.0145\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 223189.7656 - mean_absolute_error: 144.0217 - val_loss: 261831.2031 - val_mean_absolute_error: 148.9264\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 154891.2344 - mean_absolute_error: 129.3167 - val_loss: 664092.6250 - val_mean_absolute_error: 263.1660\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 441924.8750 - mean_absolute_error: 202.9517 - val_loss: 781363.7500 - val_mean_absolute_error: 297.9342\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 568006.5625 - mean_absolute_error: 241.7491 - val_loss: 357460.3125 - val_mean_absolute_error: 247.2670\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 313246.0625 - mean_absolute_error: 164.1760 - val_loss: 778442.5625 - val_mean_absolute_error: 330.1433\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 262849.6875 - mean_absolute_error: 178.1592 - val_loss: 256430.6875 - val_mean_absolute_error: 181.2025\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 85788.7109 - mean_absolute_error: 109.5634 - val_loss: 274124.4688 - val_mean_absolute_error: 157.4501\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 37766.7070 - mean_absolute_error: 88.6850 - val_loss: 660688.9375 - val_mean_absolute_error: 241.1060\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 85374.9609 - mean_absolute_error: 106.6843 - val_loss: 267468.5938 - val_mean_absolute_error: 171.7951\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 31387.1523 - mean_absolute_error: 83.1585 - val_loss: 387538.0938 - val_mean_absolute_error: 174.5782\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 30580.5820 - mean_absolute_error: 76.9342 - val_loss: 222981.3594 - val_mean_absolute_error: 145.0944\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 46972.5508 - mean_absolute_error: 86.0273 - val_loss: 272486.0938 - val_mean_absolute_error: 141.8027\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 44545.2422 - mean_absolute_error: 81.3758 - val_loss: 295722.8750 - val_mean_absolute_error: 154.1732\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 41468.4414 - mean_absolute_error: 80.2055 - val_loss: 277718.1562 - val_mean_absolute_error: 146.7114\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 22131.1172 - mean_absolute_error: 72.1553 - val_loss: 306269.8438 - val_mean_absolute_error: 153.9744\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 27487.1387 - mean_absolute_error: 74.7470 - val_loss: 389489.6875 - val_mean_absolute_error: 163.9812\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 29605.4668 - mean_absolute_error: 79.8108 - val_loss: 559495.8750 - val_mean_absolute_error: 203.6865\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 40793.3516 - mean_absolute_error: 88.3879 - val_loss: 356421.6250 - val_mean_absolute_error: 152.4451\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 38680.5664 - mean_absolute_error: 86.5539 - val_loss: 264726.2188 - val_mean_absolute_error: 178.4284\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 86411.2891 - mean_absolute_error: 103.4596 - val_loss: 522828.9688 - val_mean_absolute_error: 197.0142\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1052644.2500 - mean_absolute_error: 237.9214 - val_loss: 283839.5312 - val_mean_absolute_error: 194.2483\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 464940.3125 - mean_absolute_error: 229.2709 - val_loss: 674202.3750 - val_mean_absolute_error: 242.9071\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 782482.0625 - mean_absolute_error: 261.6435 - val_loss: 342917.7188 - val_mean_absolute_error: 182.4604\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 285385.3750 - mean_absolute_error: 174.1014 - val_loss: 405770.9062 - val_mean_absolute_error: 253.2423\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 342950.7812 - mean_absolute_error: 194.3699 - val_loss: 552000.9375 - val_mean_absolute_error: 299.6059\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 769137.8125 - mean_absolute_error: 250.4554 - val_loss: 723015.5625 - val_mean_absolute_error: 349.4302\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 4097618.5000 - mean_absolute_error: 498.1702 - val_loss: 14431619.0000 - val_mean_absolute_error: 1557.7273\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 15418574.0000 - mean_absolute_error: 1162.2916 - val_loss: 2493266.2500 - val_mean_absolute_error: 594.2900\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2322827.2500 - mean_absolute_error: 484.1021 - val_loss: 4372275.5000 - val_mean_absolute_error: 785.4785\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 4261692.0000 - mean_absolute_error: 517.6409 - val_loss: 1361640.7500 - val_mean_absolute_error: 462.4399\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 4692429.0000 - mean_absolute_error: 584.9156 - val_loss: 4786445.0000 - val_mean_absolute_error: 745.8561\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1047870.5000 - mean_absolute_error: 330.0489 - val_loss: 1366545.5000 - val_mean_absolute_error: 377.5514\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 417413.8125 - mean_absolute_error: 220.0991 - val_loss: 263583.9688 - val_mean_absolute_error: 223.2465\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 349720.7500 - mean_absolute_error: 174.1076 - val_loss: 765592.5625 - val_mean_absolute_error: 346.3660\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 829035.3125 - mean_absolute_error: 263.9946 - val_loss: 201783.4531 - val_mean_absolute_error: 171.4074\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 752828.3125 - mean_absolute_error: 252.4604 - val_loss: 4188213.0000 - val_mean_absolute_error: 711.2077\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 844350.6875 - mean_absolute_error: 251.2887 - val_loss: 709534.5625 - val_mean_absolute_error: 302.6316\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 620995.1250 - mean_absolute_error: 222.4776 - val_loss: 179446.1562 - val_mean_absolute_error: 154.1282\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 188138.6250 - mean_absolute_error: 145.4426 - val_loss: 1288565.6250 - val_mean_absolute_error: 374.4265\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 408078.9062 - mean_absolute_error: 210.6272 - val_loss: 265642.7500 - val_mean_absolute_error: 205.8500\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 146750.5469 - mean_absolute_error: 141.7084 - val_loss: 202782.1094 - val_mean_absolute_error: 174.5399\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 85903.7344 - mean_absolute_error: 127.1529 - val_loss: 208636.3906 - val_mean_absolute_error: 146.8995\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 55521.0547 - mean_absolute_error: 106.4345 - val_loss: 314545.8750 - val_mean_absolute_error: 168.6133\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 50613.9570 - mean_absolute_error: 107.9381 - val_loss: 262016.6406 - val_mean_absolute_error: 150.5720\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 57530.1211 - mean_absolute_error: 101.0050 - val_loss: 196355.2031 - val_mean_absolute_error: 149.9047\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 29729.8574 - mean_absolute_error: 91.1205 - val_loss: 276496.7500 - val_mean_absolute_error: 147.4732\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 37175.1836 - mean_absolute_error: 90.3314 - val_loss: 304458.2500 - val_mean_absolute_error: 153.5345\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 44994.9062 - mean_absolute_error: 91.1485 - val_loss: 296757.5000 - val_mean_absolute_error: 146.9813\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 55839.5859 - mean_absolute_error: 93.6878 - val_loss: 261796.9375 - val_mean_absolute_error: 137.9000\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 182681.1094 - mean_absolute_error: 141.8195 - val_loss: 283421.5000 - val_mean_absolute_error: 184.4070\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 418327.9062 - mean_absolute_error: 189.5284 - val_loss: 440888.9688 - val_mean_absolute_error: 254.6432\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 311959.9688 - mean_absolute_error: 183.8293 - val_loss: 365421.0312 - val_mean_absolute_error: 238.0069\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 149908.2031 - mean_absolute_error: 136.8557 - val_loss: 231835.5625 - val_mean_absolute_error: 178.5703\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 148132.2188 - mean_absolute_error: 131.9113 - val_loss: 419765.9062 - val_mean_absolute_error: 180.5218\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 251290.9062 - mean_absolute_error: 153.1588 - val_loss: 339382.1562 - val_mean_absolute_error: 193.1901\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 713168.3750 - mean_absolute_error: 234.8156 - val_loss: 3302501.0000 - val_mean_absolute_error: 629.5197\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 506766.5312 - mean_absolute_error: 232.0141 - val_loss: 1687586.5000 - val_mean_absolute_error: 372.9488\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 990358.0625 - mean_absolute_error: 258.0485 - val_loss: 1405408.5000 - val_mean_absolute_error: 459.3623\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 939751.8125 - mean_absolute_error: 238.7149 - val_loss: 1356494.0000 - val_mean_absolute_error: 392.8489\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1534118.7500 - mean_absolute_error: 374.8940 - val_loss: 2025395.1250 - val_mean_absolute_error: 540.2853\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 794199.3750 - mean_absolute_error: 260.4484 - val_loss: 1295091.8750 - val_mean_absolute_error: 377.0692\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 435262.6875 - mean_absolute_error: 227.0750 - val_loss: 599193.0000 - val_mean_absolute_error: 297.7960\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 260759.0781 - mean_absolute_error: 172.2168 - val_loss: 409251.0312 - val_mean_absolute_error: 207.9962\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 116851.6953 - mean_absolute_error: 131.3445 - val_loss: 978589.0625 - val_mean_absolute_error: 268.0569\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 66704.8750 - mean_absolute_error: 103.6126 - val_loss: 912185.7500 - val_mean_absolute_error: 252.6643\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 44447.6680 - mean_absolute_error: 91.0675 - val_loss: 400619.5000 - val_mean_absolute_error: 204.9644\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 125294.6172 - mean_absolute_error: 124.4714 - val_loss: 440079.5000 - val_mean_absolute_error: 183.7988\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 89899.7578 - mean_absolute_error: 105.8550 - val_loss: 963476.3750 - val_mean_absolute_error: 304.8235\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 193972.0312 - mean_absolute_error: 133.1852 - val_loss: 330172.7500 - val_mean_absolute_error: 155.9262\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 88665.4922 - mean_absolute_error: 108.5930 - val_loss: 364300.3125 - val_mean_absolute_error: 238.6130\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 147951.4375 - mean_absolute_error: 130.7963 - val_loss: 438070.7188 - val_mean_absolute_error: 158.9541\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 37578.5898 - mean_absolute_error: 90.4564 - val_loss: 659602.9375 - val_mean_absolute_error: 205.1833\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 33290.2344 - mean_absolute_error: 87.3160 - val_loss: 511509.2812 - val_mean_absolute_error: 187.2184\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 29281.3828 - mean_absolute_error: 82.7235 - val_loss: 409780.5312 - val_mean_absolute_error: 164.0843\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 23265.0586 - mean_absolute_error: 76.3726 - val_loss: 415227.7812 - val_mean_absolute_error: 159.2797\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 25871.1582 - mean_absolute_error: 75.7900 - val_loss: 595476.1875 - val_mean_absolute_error: 198.7733\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 374589.2500 - mean_absolute_error: 165.6616 - val_loss: 268423.9062 - val_mean_absolute_error: 162.9066\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 110830.3125 - mean_absolute_error: 127.5583 - val_loss: 249471.7500 - val_mean_absolute_error: 117.6847\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 155084.4531 - mean_absolute_error: 118.8775 - val_loss: 310734.8125 - val_mean_absolute_error: 149.5190\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 56557.2305 - mean_absolute_error: 92.7710 - val_loss: 394980.1875 - val_mean_absolute_error: 159.1668\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 26128.9883 - mean_absolute_error: 76.0186 - val_loss: 562280.5625 - val_mean_absolute_error: 181.1667\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 48557.1406 - mean_absolute_error: 90.0405 - val_loss: 430320.4688 - val_mean_absolute_error: 166.8830\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 213306.4062 - mean_absolute_error: 143.1342 - val_loss: 342728.1562 - val_mean_absolute_error: 221.3099\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 283145.7500 - mean_absolute_error: 136.0461 - val_loss: 577639.8750 - val_mean_absolute_error: 297.6870\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 273091.3438 - mean_absolute_error: 178.9070 - val_loss: 277772.5312 - val_mean_absolute_error: 152.0095\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 203132.9688 - mean_absolute_error: 133.5504 - val_loss: 1306381.2500 - val_mean_absolute_error: 360.1535\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 812923.1875 - mean_absolute_error: 223.9434 - val_loss: 674370.3750 - val_mean_absolute_error: 289.2727\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1501279.8750 - mean_absolute_error: 318.4414 - val_loss: 442584.2188 - val_mean_absolute_error: 240.9290\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 726630.1250 - mean_absolute_error: 282.9908 - val_loss: 216001.6406 - val_mean_absolute_error: 173.2904\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 247859.1875 - mean_absolute_error: 158.9090 - val_loss: 819841.8125 - val_mean_absolute_error: 286.2209\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 222284.7500 - mean_absolute_error: 174.6268 - val_loss: 997677.7500 - val_mean_absolute_error: 291.0993\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 154607.6406 - mean_absolute_error: 134.7534 - val_loss: 244103.9062 - val_mean_absolute_error: 168.1944\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 66065.0625 - mean_absolute_error: 108.2902 - val_loss: 304683.3125 - val_mean_absolute_error: 163.1504\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 78060.7422 - mean_absolute_error: 105.4406 - val_loss: 365261.3750 - val_mean_absolute_error: 216.8445\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 173547.7031 - mean_absolute_error: 137.3007 - val_loss: 305673.2188 - val_mean_absolute_error: 168.1588\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 189230.8594 - mean_absolute_error: 137.7921 - val_loss: 623167.6250 - val_mean_absolute_error: 250.9972\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 69149.2266 - mean_absolute_error: 98.8909 - val_loss: 407896.7812 - val_mean_absolute_error: 158.5441\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 41013.3594 - mean_absolute_error: 82.5598 - val_loss: 439308.1250 - val_mean_absolute_error: 173.4503\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 45137.5078 - mean_absolute_error: 86.5390 - val_loss: 313005.6875 - val_mean_absolute_error: 180.3506\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 115477.4688 - mean_absolute_error: 106.5855 - val_loss: 318116.5938 - val_mean_absolute_error: 166.1683\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 108687.5312 - mean_absolute_error: 105.8779 - val_loss: 343518.5312 - val_mean_absolute_error: 158.3663\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 869166.5625 - mean_absolute_error: 230.0655 - val_loss: 6639784.5000 - val_mean_absolute_error: 869.3798\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1379848.8750 - mean_absolute_error: 342.5671 - val_loss: 2145002.5000 - val_mean_absolute_error: 429.1023\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 912621.5625 - mean_absolute_error: 230.7072 - val_loss: 306084.1250 - val_mean_absolute_error: 203.8687\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 219816.7031 - mean_absolute_error: 145.3452 - val_loss: 301434.5625 - val_mean_absolute_error: 172.5025\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 93474.6797 - mean_absolute_error: 114.6887 - val_loss: 497720.5312 - val_mean_absolute_error: 186.3719\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 38158.8555 - mean_absolute_error: 85.3968 - val_loss: 512706.3750 - val_mean_absolute_error: 181.2581\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 32063.0391 - mean_absolute_error: 79.6502 - val_loss: 565467.0000 - val_mean_absolute_error: 186.4464\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 43871.5586 - mean_absolute_error: 83.6393 - val_loss: 447901.9688 - val_mean_absolute_error: 168.2884\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 62153.2891 - mean_absolute_error: 99.6954 - val_loss: 309060.7812 - val_mean_absolute_error: 165.4373\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 92344.2422 - mean_absolute_error: 104.6836 - val_loss: 324799.1562 - val_mean_absolute_error: 209.9563\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 69287.9062 - mean_absolute_error: 98.4432 - val_loss: 477760.9688 - val_mean_absolute_error: 175.8773\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 30921.2441 - mean_absolute_error: 77.3011 - val_loss: 449609.9688 - val_mean_absolute_error: 175.9367\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 35714.7891 - mean_absolute_error: 79.5521 - val_loss: 376144.0938 - val_mean_absolute_error: 178.8459\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 22511.1719 - mean_absolute_error: 72.3299 - val_loss: 487430.0938 - val_mean_absolute_error: 165.1488\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 25642.7344 - mean_absolute_error: 71.4904 - val_loss: 529600.6250 - val_mean_absolute_error: 167.3047\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 44426.6602 - mean_absolute_error: 78.8924 - val_loss: 510585.0938 - val_mean_absolute_error: 173.0322\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 131079.2500 - mean_absolute_error: 112.4150 - val_loss: 277866.5000 - val_mean_absolute_error: 135.7942\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 189943.7500 - mean_absolute_error: 136.4287 - val_loss: 500461.9688 - val_mean_absolute_error: 279.2751\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 185958.6250 - mean_absolute_error: 131.6189 - val_loss: 419358.9062 - val_mean_absolute_error: 238.5544\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 219153.4219 - mean_absolute_error: 142.6363 - val_loss: 510542.7188 - val_mean_absolute_error: 194.9469\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 39245.7617 - mean_absolute_error: 86.2624 - val_loss: 310643.5312 - val_mean_absolute_error: 156.2124\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 38467.9922 - mean_absolute_error: 85.6267 - val_loss: 275304.6562 - val_mean_absolute_error: 150.1574\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 46180.7891 - mean_absolute_error: 83.9682 - val_loss: 457470.4688 - val_mean_absolute_error: 160.5561\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 86917.9531 - mean_absolute_error: 97.7605 - val_loss: 296650.0625 - val_mean_absolute_error: 169.7081\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 797902.0000 - mean_absolute_error: 226.0270 - val_loss: 2339139.5000 - val_mean_absolute_error: 555.1354\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1595989.3750 - mean_absolute_error: 355.1337 - val_loss: 1090795.8750 - val_mean_absolute_error: 350.7832\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 632569.6250 - mean_absolute_error: 240.0189 - val_loss: 506360.0000 - val_mean_absolute_error: 269.0081\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 280478.7500 - mean_absolute_error: 173.9077 - val_loss: 541722.0625 - val_mean_absolute_error: 226.6810\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 102134.1719 - mean_absolute_error: 135.1169 - val_loss: 471643.1875 - val_mean_absolute_error: 223.2504\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 132521.9375 - mean_absolute_error: 127.1709 - val_loss: 670662.8125 - val_mean_absolute_error: 242.8275\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1137876.3750 - mean_absolute_error: 285.9961 - val_loss: 2174784.5000 - val_mean_absolute_error: 572.0527\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 828577.2500 - mean_absolute_error: 276.8097 - val_loss: 4804892.5000 - val_mean_absolute_error: 663.6030\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 776616.3125 - mean_absolute_error: 271.8919 - val_loss: 601825.5625 - val_mean_absolute_error: 249.7495\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 485421.9688 - mean_absolute_error: 199.9738 - val_loss: 408933.5000 - val_mean_absolute_error: 185.4649\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 244278.5156 - mean_absolute_error: 158.1375 - val_loss: 327267.2188 - val_mean_absolute_error: 217.1687\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 113478.8438 - mean_absolute_error: 125.3722 - val_loss: 316822.3750 - val_mean_absolute_error: 188.2318\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 51551.1445 - mean_absolute_error: 102.9155 - val_loss: 397175.9688 - val_mean_absolute_error: 196.0432\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 27794.3398 - mean_absolute_error: 89.5422 - val_loss: 319711.4688 - val_mean_absolute_error: 194.5820\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 47550.3633 - mean_absolute_error: 92.0286 - val_loss: 319776.0938 - val_mean_absolute_error: 177.6884\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 79893.2578 - mean_absolute_error: 107.9103 - val_loss: 375044.7812 - val_mean_absolute_error: 181.0446\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 98841.1562 - mean_absolute_error: 102.4665 - val_loss: 292605.6875 - val_mean_absolute_error: 151.0447\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 115386.7266 - mean_absolute_error: 107.6008 - val_loss: 673747.0625 - val_mean_absolute_error: 261.9270\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 116951.9609 - mean_absolute_error: 132.8085 - val_loss: 702408.9375 - val_mean_absolute_error: 223.3783\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 357377.4062 - mean_absolute_error: 177.5950 - val_loss: 421226.2188 - val_mean_absolute_error: 201.6515\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 115855.0391 - mean_absolute_error: 131.7419 - val_loss: 540032.4375 - val_mean_absolute_error: 281.3351\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 183277.0781 - mean_absolute_error: 144.9820 - val_loss: 420330.7812 - val_mean_absolute_error: 184.3846\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 64263.1094 - mean_absolute_error: 112.9318 - val_loss: 488196.3750 - val_mean_absolute_error: 174.0215\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 31151.0410 - mean_absolute_error: 88.2630 - val_loss: 754679.5625 - val_mean_absolute_error: 243.0738\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 82901.4375 - mean_absolute_error: 111.7244 - val_loss: 378288.3750 - val_mean_absolute_error: 203.5787\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 50709.7812 - mean_absolute_error: 93.4889 - val_loss: 365730.1875 - val_mean_absolute_error: 227.4166\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 75406.6250 - mean_absolute_error: 116.9910 - val_loss: 510881.1875 - val_mean_absolute_error: 212.7062\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 39160.0117 - mean_absolute_error: 86.2815 - val_loss: 337464.6875 - val_mean_absolute_error: 158.2987\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 33481.2031 - mean_absolute_error: 88.1693 - val_loss: 312563.1250 - val_mean_absolute_error: 170.6713\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 30217.5215 - mean_absolute_error: 78.3491 - val_loss: 388673.1250 - val_mean_absolute_error: 164.0147\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 22701.4355 - mean_absolute_error: 74.0897 - val_loss: 361017.0000 - val_mean_absolute_error: 161.8454\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 19412.2617 - mean_absolute_error: 70.5608 - val_loss: 357625.1250 - val_mean_absolute_error: 165.3441\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 24892.6016 - mean_absolute_error: 74.8242 - val_loss: 320377.7500 - val_mean_absolute_error: 167.6950\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 23338.2266 - mean_absolute_error: 77.4944 - val_loss: 440172.4688 - val_mean_absolute_error: 187.2419\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 59662.4102 - mean_absolute_error: 99.3876 - val_loss: 403535.3750 - val_mean_absolute_error: 165.2184\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 516822.0000 - mean_absolute_error: 168.5356 - val_loss: 660065.5625 - val_mean_absolute_error: 270.7754\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 912228.1875 - mean_absolute_error: 240.7877 - val_loss: 197938.2344 - val_mean_absolute_error: 146.1050\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1182047.3750 - mean_absolute_error: 270.9938 - val_loss: 572248.7500 - val_mean_absolute_error: 233.2744\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 448823.1250 - mean_absolute_error: 188.4784 - val_loss: 1083478.0000 - val_mean_absolute_error: 317.8705\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 254099.5781 - mean_absolute_error: 158.7395 - val_loss: 422727.7812 - val_mean_absolute_error: 222.2486\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 191013.7656 - mean_absolute_error: 135.4190 - val_loss: 253841.9531 - val_mean_absolute_error: 178.0480\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 75523.3516 - mean_absolute_error: 113.2056 - val_loss: 436114.5312 - val_mean_absolute_error: 196.2777\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 74555.9688 - mean_absolute_error: 97.4913 - val_loss: 359967.1250 - val_mean_absolute_error: 166.3609\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 51266.4922 - mean_absolute_error: 89.9794 - val_loss: 453197.3750 - val_mean_absolute_error: 185.5786\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 107739.5156 - mean_absolute_error: 109.0452 - val_loss: 397431.2812 - val_mean_absolute_error: 174.0351\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 44579.7773 - mean_absolute_error: 88.7796 - val_loss: 268764.1875 - val_mean_absolute_error: 141.3240\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 26058.9297 - mean_absolute_error: 75.6247 - val_loss: 273999.8750 - val_mean_absolute_error: 179.9524\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 43229.4609 - mean_absolute_error: 79.4658 - val_loss: 294895.6875 - val_mean_absolute_error: 188.8099\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 104163.3672 - mean_absolute_error: 104.5049 - val_loss: 413176.5938 - val_mean_absolute_error: 255.1426\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 136988.4531 - mean_absolute_error: 112.9945 - val_loss: 305969.7188 - val_mean_absolute_error: 209.0570\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 165393.1094 - mean_absolute_error: 124.3562 - val_loss: 255938.5625 - val_mean_absolute_error: 177.9699\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 278560.1875 - mean_absolute_error: 159.1321 - val_loss: 269133.4688 - val_mean_absolute_error: 196.1787\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 205005.9219 - mean_absolute_error: 139.4249 - val_loss: 318748.0312 - val_mean_absolute_error: 176.2204\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 27108.5664 - mean_absolute_error: 74.0037 - val_loss: 230066.8594 - val_mean_absolute_error: 171.8814\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 35605.8359 - mean_absolute_error: 78.6227 - val_loss: 286545.0312 - val_mean_absolute_error: 187.2552\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 46880.3438 - mean_absolute_error: 89.3587 - val_loss: 193688.2344 - val_mean_absolute_error: 147.2292\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 82920.6250 - mean_absolute_error: 94.5035 - val_loss: 734120.1875 - val_mean_absolute_error: 260.0450\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1894019.8750 - mean_absolute_error: 332.8594 - val_loss: 413219.5312 - val_mean_absolute_error: 252.6641\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 868190.9375 - mean_absolute_error: 246.2165 - val_loss: 4084729.7500 - val_mean_absolute_error: 669.7162\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1951595.1250 - mean_absolute_error: 333.2836 - val_loss: 720789.0625 - val_mean_absolute_error: 300.1078\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1077384.0000 - mean_absolute_error: 255.4860 - val_loss: 478133.3125 - val_mean_absolute_error: 299.4944\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1865064.7500 - mean_absolute_error: 352.1099 - val_loss: 5368741.0000 - val_mean_absolute_error: 801.8610\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1323983.1250 - mean_absolute_error: 299.7384 - val_loss: 4246870.5000 - val_mean_absolute_error: 668.5158\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1981325.2500 - mean_absolute_error: 374.6657 - val_loss: 15979402.0000 - val_mean_absolute_error: 1410.1289\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11519158.0000 - mean_absolute_error: 920.6198 - val_loss: 4598158.0000 - val_mean_absolute_error: 768.9451\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2850752.5000 - mean_absolute_error: 413.8730 - val_loss: 6736320.0000 - val_mean_absolute_error: 823.5630\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3949974.5000 - mean_absolute_error: 514.7504 - val_loss: 3126467.7500 - val_mean_absolute_error: 642.8365\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 4738648.5000 - mean_absolute_error: 519.2489 - val_loss: 3061638.5000 - val_mean_absolute_error: 610.7784\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3997340.2500 - mean_absolute_error: 505.5532 - val_loss: 18726334.0000 - val_mean_absolute_error: 1489.8126\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3638964.0000 - mean_absolute_error: 493.7608 - val_loss: 1778955.5000 - val_mean_absolute_error: 474.2936\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1303778.3750 - mean_absolute_error: 346.0555 - val_loss: 1018909.2500 - val_mean_absolute_error: 335.2476\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 589335.8750 - mean_absolute_error: 251.5802 - val_loss: 1539344.7500 - val_mean_absolute_error: 390.3149\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 416005.8438 - mean_absolute_error: 185.7892 - val_loss: 387254.3750 - val_mean_absolute_error: 241.4021\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 238142.5781 - mean_absolute_error: 165.1009 - val_loss: 2069613.6250 - val_mean_absolute_error: 471.6357\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 481264.2812 - mean_absolute_error: 187.8266 - val_loss: 564066.8125 - val_mean_absolute_error: 248.1383\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 140727.8594 - mean_absolute_error: 132.8065 - val_loss: 402495.0000 - val_mean_absolute_error: 205.9740\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 109886.0156 - mean_absolute_error: 119.0831 - val_loss: 587883.7500 - val_mean_absolute_error: 233.4644\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 77378.8750 - mean_absolute_error: 105.7757 - val_loss: 484465.9688 - val_mean_absolute_error: 200.5023\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 66453.0234 - mean_absolute_error: 104.3102 - val_loss: 431638.4688 - val_mean_absolute_error: 189.6661\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 110466.9609 - mean_absolute_error: 114.0981 - val_loss: 402203.2812 - val_mean_absolute_error: 204.7532\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 268479.2500 - mean_absolute_error: 158.9354 - val_loss: 649322.2500 - val_mean_absolute_error: 241.9271\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 403868.0312 - mean_absolute_error: 159.8401 - val_loss: 1959293.1250 - val_mean_absolute_error: 477.5674\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 412375.6562 - mean_absolute_error: 206.7702 - val_loss: 673799.5625 - val_mean_absolute_error: 236.2507\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 226745.9062 - mean_absolute_error: 152.3952 - val_loss: 482893.1250 - val_mean_absolute_error: 231.1339\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 212429.7969 - mean_absolute_error: 138.0665 - val_loss: 667635.8750 - val_mean_absolute_error: 300.8148\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 401258.4062 - mean_absolute_error: 203.0072 - val_loss: 757673.7500 - val_mean_absolute_error: 260.6939\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 256149.9688 - mean_absolute_error: 169.0688 - val_loss: 737013.7500 - val_mean_absolute_error: 225.2062\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 45974.5391 - mean_absolute_error: 98.0346 - val_loss: 500964.8750 - val_mean_absolute_error: 171.3136\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 34505.8281 - mean_absolute_error: 85.8753 - val_loss: 447187.6875 - val_mean_absolute_error: 198.9363\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 29020.6309 - mean_absolute_error: 81.7374 - val_loss: 700058.4375 - val_mean_absolute_error: 211.2405\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 34577.0859 - mean_absolute_error: 82.4558 - val_loss: 780662.0000 - val_mean_absolute_error: 213.5736\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 159797.3594 - mean_absolute_error: 121.6999 - val_loss: 542530.8750 - val_mean_absolute_error: 187.5930\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 52023.2852 - mean_absolute_error: 91.1447 - val_loss: 446811.7812 - val_mean_absolute_error: 203.7110\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 62373.3867 - mean_absolute_error: 94.5632 - val_loss: 466292.3125 - val_mean_absolute_error: 172.9892\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 38356.4727 - mean_absolute_error: 87.2129 - val_loss: 530482.7500 - val_mean_absolute_error: 185.8594\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 32223.2754 - mean_absolute_error: 80.1302 - val_loss: 387987.4062 - val_mean_absolute_error: 173.4712\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 94364.6250 - mean_absolute_error: 109.0649 - val_loss: 433087.5000 - val_mean_absolute_error: 211.1116\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 100694.1484 - mean_absolute_error: 105.2907 - val_loss: 451119.9688 - val_mean_absolute_error: 163.0794\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 32659.3594 - mean_absolute_error: 80.3698 - val_loss: 346726.4688 - val_mean_absolute_error: 149.5707\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 105436.6250 - mean_absolute_error: 108.8214 - val_loss: 668976.5625 - val_mean_absolute_error: 224.4124\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   mode='min',\n",
    "                   patience=50,\n",
    "                   restore_best_weights = True)\n",
    "# Train the final model on the entire training set\n",
    "history = final_model.fit(X_train, y_train,\n",
    "                validation_data = (X_val, y_val),\n",
    "                callbacks=[es],\n",
    "                epochs=best_params['epochs'],\n",
    "                batch_size=best_params['batch_size'],\n",
    "                verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T22:20:23.804217500Z",
     "start_time": "2024-02-05T22:19:41.633666900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyse learn history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[88], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# let's see the training and validation accuracy by epoch\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m history_dict \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory\n\u001B[0;32m      3\u001B[0m loss_values \u001B[38;5;241m=\u001B[39m history_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;66;03m# you can change this\u001B[39;00m\n\u001B[0;32m      4\u001B[0m val_loss_values \u001B[38;5;241m=\u001B[39m history_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;66;03m# you can also change this\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'KerasRegressor' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# let's see the training and validation accuracy by epoch\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss'] # you can change this\n",
    "val_loss_values = history_dict['val_loss'] # you can also change this\n",
    "epochs = range(1, len(loss_values) + 1) # range of X (no. of epochs)\n",
    "plt.plot(epochs, loss_values, 'blue', label='Train set loss')\n",
    "plt.plot(epochs, val_loss_values, 'orange', label='Validation set loss')\n",
    "#plt.title('Training and testing loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T22:20:30.926294200Z",
     "start_time": "2024-02-05T22:20:30.447391400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[89], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m loss_values1 \u001B[38;5;241m=\u001B[39m history_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;66;03m# you can change this\u001B[39;00m\n\u001B[0;32m      2\u001B[0m val_loss_values1 \u001B[38;5;241m=\u001B[39m history_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_mae\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;66;03m# you can also change this\u001B[39;00m\n\u001B[0;32m      3\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(loss_values1) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;66;03m# range of X (no. of epochs)\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history_dict' is not defined"
     ]
    }
   ],
   "source": [
    "loss_values1 = history_dict['mae'] # you can change this\n",
    "val_loss_values1 = history_dict['val_mae'] # you can also change this\n",
    "epochs = range(1, len(loss_values1) + 1) # range of X (no. of epochs)\n",
    "plt.plot(epochs, loss_values1, 'blue', label='Train set MAE')\n",
    "plt.plot(epochs, val_loss_values1, 'orange', label='Validation set MAE')\n",
    "#plt.title('Training and testing MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T22:20:45.480671800Z",
     "start_time": "2024-02-05T22:20:45.409323900Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
