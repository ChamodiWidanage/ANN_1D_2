{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf",
    "ExecuteTime": {
     "end_time": "2023-12-25T05:11:05.035422200Z",
     "start_time": "2023-12-25T05:11:05.035422200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM",
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:31.636438200Z",
     "start_time": "2023-12-25T05:12:31.226849600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588 entries, 0 to 587\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Explosive type          588 non-null    object \n",
      " 1   Explosive mass          588 non-null    float64\n",
      " 2   Standoff distance       588 non-null    float64\n",
      " 3   Peak incident pressure  588 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 18.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('P_Dataset4.xlsx')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:33.988934800Z",
     "start_time": "2023-12-25T05:12:33.941400700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588 entries, 0 to 587\n",
      "Data columns (total 5 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Explosive mass                588 non-null    float64\n",
      " 1   Standoff distance             588 non-null    float64\n",
      " 2   Peak incident pressure        588 non-null    float64\n",
      " 3   Explosive type_Composition B  588 non-null    uint8  \n",
      " 4   Explosive type_TNT            588 non-null    uint8  \n",
      "dtypes: float64(3), uint8(2)\n",
      "memory usage: 15.1 KB\n"
     ]
    }
   ],
   "source": [
    "# convert categorical variable into dummy variables\n",
    "dataset = pd.get_dummies(dataset, columns=['Explosive type'])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:36.004735600Z",
     "start_time": "2023-12-25T05:12:35.973287500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Explosive mass  Standoff distance  Peak incident pressure  \\\n0             0.5                1.0                 597.460   \n1             0.5                1.5                 283.258   \n2             0.5                2.5                 163.904   \n3             0.5                3.5                 135.678   \n4             0.5                4.5                 124.039   \n\n   Explosive type_Composition B  Explosive type_TNT  \n0                             0                   1  \n1                             0                   1  \n2                             0                   1  \n3                             0                   1  \n4                             0                   1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Explosive mass</th>\n      <th>Standoff distance</th>\n      <th>Peak incident pressure</th>\n      <th>Explosive type_Composition B</th>\n      <th>Explosive type_TNT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>597.460</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>1.5</td>\n      <td>283.258</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>2.5</td>\n      <td>163.904</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>3.5</td>\n      <td>135.678</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>4.5</td>\n      <td>124.039</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:37.667725900Z",
     "start_time": "2023-12-25T05:12:37.658646500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588, 4) (588,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset[('Peak incident pressure')]\n",
    "X = dataset.drop('Peak incident pressure', axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:39.009691900Z",
     "start_time": "2023-12-25T05:12:39.009691900Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx",
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:41.253672800Z",
     "start_time": "2023-12-25T05:12:41.253672800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test,\n",
    "                                                y_test,\n",
    "                                                test_size = 0.5,\n",
    "                                                random_state = 71)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:43.331455400Z",
     "start_time": "2023-12-25T05:12:43.331455400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55550177 -0.22203742  1.          0.        ]\n",
      " [-0.64547091  0.27937676  1.          0.        ]\n",
      " [ 0.36587451  0.78079094  1.          0.        ]\n",
      " ...\n",
      " [-1.15114363  0.44651482  0.          1.        ]\n",
      " [-1.53039816  0.1122387   0.          1.        ]\n",
      " [-0.39263456 -1.39200384  0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:,0:2] = sc.fit_transform(X_train[:, 0:2])\n",
    "print (X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:46.393292300Z",
     "start_time": "2023-12-25T05:12:46.377247Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.53039816 -0.22203742  1.          0.        ]\n",
      " [-0.39263456 -0.22203742  1.          0.        ]\n",
      " [-0.1397982  -1.39200384  1.          0.        ]\n",
      " [-0.64547091 -1.05772772  1.          0.        ]\n",
      " [ 0.61871086  0.1122387   0.          1.        ]\n",
      " [ 1.5668472  -0.05489936  1.          0.        ]\n",
      " [-0.39263456 -1.5591419   1.          0.        ]\n",
      " [ 0.61871086  0.27937676  0.          1.        ]\n",
      " [ 0.87154722  0.1122387   0.          1.        ]\n",
      " [-0.39263456 -0.89058966  0.          1.        ]\n",
      " [-0.64547091  1.53291221  0.          1.        ]\n",
      " [ 0.87154722 -0.89058966  0.          1.        ]\n",
      " [-1.40397998 -1.05772772  1.          0.        ]\n",
      " [-1.40397998  0.27937676  1.          0.        ]\n",
      " [ 0.80833813 -1.5591419   1.          0.        ]\n",
      " [-0.89830727 -0.7234516   0.          1.        ]\n",
      " [ 0.80833813 -0.7234516   1.          0.        ]\n",
      " [-0.1397982  -0.55631354  1.          0.        ]\n",
      " [-0.39263456 -0.05489936  1.          0.        ]\n",
      " [-0.64547091 -1.5591419   1.          0.        ]\n",
      " [ 0.61871086  0.44651482  0.          1.        ]\n",
      " [-0.64547091 -1.39200384  1.          0.        ]\n",
      " [ 0.87154722  0.61365288  0.          1.        ]\n",
      " [ 0.80833813  1.28220512  1.          0.        ]\n",
      " [-0.64547091  0.61365288  0.          1.        ]\n",
      " [ 0.80833813 -1.22486578  1.          0.        ]\n",
      " [-0.89830727  0.947929    1.          0.        ]\n",
      " [ 1.31401084  0.27937676  1.          0.        ]\n",
      " [-1.53039816 -1.22486578  0.          1.        ]\n",
      " [-0.64547091  1.44934318  1.          0.        ]\n",
      " [-0.89830727 -0.38917548  1.          0.        ]\n",
      " [ 0.36587451  0.61365288  0.          1.        ]\n",
      " [ 0.36587451  0.947929    1.          0.        ]\n",
      " [ 0.61871086  1.53291221  0.          1.        ]\n",
      " [ 0.87154722 -1.22486578  0.          1.        ]\n",
      " [ 1.06117448  0.947929    1.          0.        ]\n",
      " [ 1.06117448 -0.22203742  1.          0.        ]\n",
      " [ 1.12438357  0.27937676  0.          1.        ]\n",
      " [ 1.5668472  -1.5591419   0.          1.        ]\n",
      " [-1.40397998 -1.22486578  0.          1.        ]\n",
      " [ 0.87154722 -1.64271093  0.          1.        ]\n",
      " [-0.64547091  0.78079094  1.          0.        ]\n",
      " [ 1.12438357 -1.39200384  0.          1.        ]\n",
      " [ 1.5668472  -0.55631354  0.          1.        ]\n",
      " [-0.89830727 -0.22203742  1.          0.        ]\n",
      " [-1.53039816  1.28220512  0.          1.        ]\n",
      " [-1.15114363 -1.22486578  1.          0.        ]\n",
      " [-0.64547091  0.61365288  1.          0.        ]\n",
      " [-1.40397998 -0.89058966  1.          0.        ]\n",
      " [-0.1397982  -0.05489936  1.          0.        ]\n",
      " [ 0.11303815 -0.89058966  0.          1.        ]\n",
      " [-1.40397998  0.44651482  1.          0.        ]\n",
      " [-0.89830727 -1.5591419   0.          1.        ]\n",
      " [-1.40397998 -0.38917548  1.          0.        ]\n",
      " [-0.39263456 -1.64271093  0.          1.        ]\n",
      " [ 1.5668472   0.44651482  0.          1.        ]\n",
      " [-1.15114363 -0.38917548  0.          1.        ]\n",
      " [ 1.5668472  -0.05489936  0.          1.        ]\n",
      " [-1.53039816 -1.39200384  1.          0.        ]\n",
      " [-0.39263456  0.1122387   0.          1.        ]\n",
      " [-0.1397982  -0.89058966  1.          0.        ]\n",
      " [ 0.87154722 -0.7234516   0.          1.        ]\n",
      " [ 0.36587451 -0.55631354  1.          0.        ]\n",
      " [ 0.36587451  0.61365288  1.          0.        ]\n",
      " [ 0.36587451  1.53291221  1.          0.        ]\n",
      " [-1.53039816 -0.7234516   0.          1.        ]\n",
      " [-0.39263456  1.11506706  0.          1.        ]\n",
      " [-1.15114363  0.1122387   0.          1.        ]\n",
      " [-0.39263456  0.27937676  1.          0.        ]\n",
      " [ 1.06117448 -0.55631354  1.          0.        ]\n",
      " [-0.89830727  1.53291221  1.          0.        ]\n",
      " [ 0.36587451 -1.22486578  1.          0.        ]\n",
      " [-0.39263456 -0.22203742  0.          1.        ]\n",
      " [ 0.36587451 -0.7234516   1.          0.        ]\n",
      " [ 0.55550177  0.44651482  1.          0.        ]\n",
      " [ 1.37721993 -1.22486578  0.          1.        ]\n",
      " [ 0.36587451 -0.89058966  0.          1.        ]\n",
      " [-1.53039816  0.61365288  1.          0.        ]\n",
      " [-0.1397982   0.1122387   1.          0.        ]\n",
      " [-1.15114363  0.44651482  1.          0.        ]\n",
      " [ 1.5668472  -1.5591419   1.          0.        ]\n",
      " [ 1.5668472  -1.39200384  1.          0.        ]\n",
      " [ 0.11303815 -1.22486578  0.          1.        ]\n",
      " [ 1.5668472   0.947929    0.          1.        ]\n",
      " [-1.40397998  0.61365288  0.          1.        ]\n",
      " [ 1.5668472  -0.38917548  0.          1.        ]\n",
      " [ 0.80833813 -0.38917548  1.          0.        ]\n",
      " [-1.53039816  0.61365288  0.          1.        ]\n",
      " [ 1.5668472  -1.05772772  0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "X_test[:,0:2] = sc.transform(X_test[:, 0:2])\n",
    "print (X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:48.189684700Z",
     "start_time": "2023-12-25T05:12:48.139562200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55550177  1.53291221  1.          0.        ]\n",
      " [-0.39263456 -0.38917548  1.          0.        ]\n",
      " [-0.89830727  0.27937676  1.          0.        ]\n",
      " [-1.53039816  1.28220512  1.          0.        ]\n",
      " [-0.39263456 -1.05772772  0.          1.        ]\n",
      " [-1.40397998 -0.05489936  1.          0.        ]\n",
      " [-1.40397998 -0.89058966  0.          1.        ]\n",
      " [-1.53039816  1.53291221  1.          0.        ]\n",
      " [ 0.55550177  0.1122387   1.          0.        ]\n",
      " [-1.53039816 -0.7234516   1.          0.        ]\n",
      " [-1.40397998  0.78079094  1.          0.        ]\n",
      " [-1.53039816  1.53291221  0.          1.        ]\n",
      " [-0.1397982  -1.64271093  1.          0.        ]\n",
      " [-1.15114363  0.27937676  1.          0.        ]\n",
      " [-0.64547091 -0.55631354  0.          1.        ]\n",
      " [ 0.80833813  1.11506706  1.          0.        ]\n",
      " [ 0.04982906 -0.05489936  1.          0.        ]\n",
      " [-0.39263456 -1.22486578  1.          0.        ]\n",
      " [-1.40397998  0.44651482  0.          1.        ]\n",
      " [-0.64547091 -1.22486578  1.          0.        ]\n",
      " [-0.64547091  0.1122387   0.          1.        ]\n",
      " [ 0.04982906 -1.64271093  1.          0.        ]\n",
      " [ 0.80833813 -0.22203742  1.          0.        ]\n",
      " [-0.39263456  0.1122387   1.          0.        ]\n",
      " [-1.53039816 -0.22203742  0.          1.        ]\n",
      " [ 1.06117448  0.78079094  1.          0.        ]\n",
      " [ 0.61871086 -1.39200384  0.          1.        ]\n",
      " [ 1.5668472   1.53291221  0.          1.        ]\n",
      " [ 0.04982906 -1.05772772  1.          0.        ]\n",
      " [-0.1397982  -0.89058966  0.          1.        ]\n",
      " [ 1.37721993 -1.64271093  0.          1.        ]\n",
      " [-0.64547091 -1.05772772  0.          1.        ]\n",
      " [-0.1397982  -1.5591419   0.          1.        ]\n",
      " [ 0.80833813 -1.05772772  1.          0.        ]\n",
      " [ 0.87154722 -1.39200384  0.          1.        ]\n",
      " [ 0.55550177  1.44934318  1.          0.        ]\n",
      " [ 1.06117448  1.28220512  1.          0.        ]\n",
      " [ 1.12438357 -1.5591419   0.          1.        ]\n",
      " [ 0.55550177 -0.89058966  1.          0.        ]\n",
      " [-1.15114363 -0.55631354  0.          1.        ]\n",
      " [ 0.11303815 -1.5591419   0.          1.        ]\n",
      " [ 0.11303815 -0.55631354  0.          1.        ]\n",
      " [ 1.31401084  1.44934318  1.          0.        ]\n",
      " [ 0.61871086 -0.05489936  0.          1.        ]\n",
      " [ 0.04982906 -1.22486578  1.          0.        ]\n",
      " [ 1.06117448  1.44934318  1.          0.        ]\n",
      " [-0.64547091  1.28220512  1.          0.        ]\n",
      " [ 1.5668472   0.1122387   1.          0.        ]\n",
      " [ 0.11303815  0.1122387   0.          1.        ]\n",
      " [-0.64547091 -0.05489936  0.          1.        ]\n",
      " [ 0.04982906  0.27937676  1.          0.        ]\n",
      " [ 0.61871086  0.947929    0.          1.        ]\n",
      " [-1.15114363  1.11506706  0.          1.        ]\n",
      " [ 0.04982906 -1.39200384  1.          0.        ]\n",
      " [-0.1397982   1.11506706  1.          0.        ]\n",
      " [ 0.80833813 -0.89058966  1.          0.        ]\n",
      " [ 0.87154722  0.27937676  0.          1.        ]\n",
      " [-0.89830727  1.44934318  1.          0.        ]\n",
      " [-0.1397982  -1.22486578  1.          0.        ]\n",
      " [-0.89830727  0.61365288  0.          1.        ]\n",
      " [ 1.12438357 -1.64271093  0.          1.        ]\n",
      " [ 0.61871086 -0.7234516   0.          1.        ]\n",
      " [ 0.11303815  1.44934318  0.          1.        ]\n",
      " [ 0.11303815 -1.64271093  0.          1.        ]\n",
      " [-1.40397998  0.1122387   0.          1.        ]\n",
      " [-0.39263456 -1.64271093  1.          0.        ]\n",
      " [ 1.31401084 -0.22203742  1.          0.        ]\n",
      " [ 0.61871086  0.61365288  0.          1.        ]\n",
      " [-0.1397982   0.44651482  0.          1.        ]\n",
      " [-0.89830727 -1.05772772  1.          0.        ]\n",
      " [-1.15114363 -1.5591419   1.          0.        ]\n",
      " [-1.15114363  0.947929    1.          0.        ]\n",
      " [-1.15114363  1.11506706  1.          0.        ]\n",
      " [-0.39263456 -1.22486578  0.          1.        ]\n",
      " [ 0.36587451  1.11506706  0.          1.        ]\n",
      " [ 1.5668472  -1.22486578  1.          0.        ]\n",
      " [ 0.55550177 -0.7234516   1.          0.        ]\n",
      " [-1.53039816  0.78079094  0.          1.        ]\n",
      " [-1.15114363 -1.05772772  0.          1.        ]\n",
      " [-1.40397998 -0.22203742  0.          1.        ]\n",
      " [ 0.36587451  0.44651482  1.          0.        ]\n",
      " [ 0.55550177  1.28220512  1.          0.        ]\n",
      " [ 0.87154722  1.28220512  0.          1.        ]\n",
      " [-0.1397982  -1.22486578  0.          1.        ]\n",
      " [-0.1397982   0.1122387   0.          1.        ]\n",
      " [ 0.36587451  1.11506706  1.          0.        ]\n",
      " [-1.40397998 -1.5591419   0.          1.        ]\n",
      " [-1.53039816  0.27937676  1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X_val[:,0:2] = sc.transform(X_val[:, 0:2])\n",
    "print (X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T05:12:49.721154100Z",
     "start_time": "2023-12-25T05:12:49.689752400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1 - Hyperparameter tuning - layers, neurons, activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T12:21:24.415238800Z",
     "start_time": "2023-12-25T12:21:24.367776500Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n",
    "\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(71)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "def FindLayerNodesLinear( last_layer_nodes):\n",
    "    layers = []\n",
    "    nodes_increment = (last_layer_nodes - 200)/ 2\n",
    "    nodes = 200\n",
    "    for i in range(1, 4):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T12:21:27.011181800Z",
     "start_time": "2023-12-25T12:21:26.982221400Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model1(last_layer_nodes, activation_func):\n",
    "    model = Sequential()\n",
    "    n_nodes = FindLayerNodesLinear(last_layer_nodes)\n",
    "    for i in range(1, 4):\n",
    "        if i==1:\n",
    "            model.add(Dense(units = 200,  input_shape=(X_train.shape[1],), activation=activation_func))\n",
    "            model.add(Dropout(0.1))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            model.add(Dropout(0.1))\n",
    "            \n",
    "    #Finally, the output layer should have a single node in binary classification\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer1 = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer = optimizer1, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "activation_func = ['relu', 'leaky_relu', 'softplus']\n",
    "last_layer_nodes = [10, 20, 30, 40, 50,60, 70, 80,90,100,110,120,130, 140, 150,160, 170, 180, 190, 200]\n",
    "\n",
    "param_grid = dict(model__activation_func = activation_func,model__last_layer_nodes = last_layer_nodes)\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model1 = KerasRegressor(model=create_model1, verbose=0, epochs = 100, batch_size = 50, random_state = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T12:23:01.298775800Z",
     "start_time": "2023-12-25T12:21:32.251154800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.958613 using {'model__activation_func': 'relu', 'model__last_layer_nodes': 10}\n",
      "0.958613 (0.018097) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 10}\n",
      "0.934811 (0.049576) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 20}\n",
      "0.934409 (0.028650) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 30}\n",
      "0.951170 (0.014944) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 40}\n",
      "0.937980 (0.032260) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 50}\n",
      "0.946756 (0.022705) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 60}\n",
      "0.936221 (0.040043) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 70}\n",
      "0.940796 (0.032936) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 80}\n",
      "0.938116 (0.027923) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 90}\n",
      "0.951490 (0.018479) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 100}\n",
      "0.951634 (0.023867) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 110}\n",
      "0.905791 (0.094457) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 120}\n",
      "0.947242 (0.020077) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 130}\n",
      "0.948373 (0.011177) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 140}\n",
      "0.924367 (0.028741) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 150}\n",
      "0.930649 (0.031556) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 160}\n",
      "0.943442 (0.033489) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 170}\n",
      "0.944401 (0.022507) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 180}\n",
      "0.950589 (0.014090) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 190}\n",
      "0.899466 (0.068132) with: {'model__activation_func': 'relu', 'model__last_layer_nodes': 200}\n",
      "0.950312 (0.023658) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 10}\n",
      "0.929584 (0.051549) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 20}\n",
      "0.940615 (0.013321) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 30}\n",
      "0.945347 (0.025688) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 40}\n",
      "0.946011 (0.014971) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 50}\n",
      "0.935047 (0.027224) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 60}\n",
      "0.940793 (0.026767) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 70}\n",
      "0.917589 (0.050999) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 80}\n",
      "0.923078 (0.045493) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 90}\n",
      "0.931042 (0.026954) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 100}\n",
      "0.931176 (0.045948) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 110}\n",
      "0.935937 (0.024224) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 120}\n",
      "0.931898 (0.031521) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 130}\n",
      "0.935238 (0.020647) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 140}\n",
      "0.923627 (0.031416) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 150}\n",
      "0.931929 (0.030089) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 160}\n",
      "0.922444 (0.034403) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 170}\n",
      "0.936763 (0.022484) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 180}\n",
      "0.927567 (0.029707) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 190}\n",
      "0.899530 (0.079198) with: {'model__activation_func': 'leaky_relu', 'model__last_layer_nodes': 200}\n",
      "0.825313 (0.163766) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 10}\n",
      "0.846319 (0.147273) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 20}\n",
      "0.833903 (0.149224) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 30}\n",
      "0.858258 (0.111910) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 40}\n",
      "0.824389 (0.165331) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 50}\n",
      "0.828122 (0.187116) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 60}\n",
      "0.854196 (0.114007) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 70}\n",
      "0.850090 (0.132671) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 80}\n",
      "0.840874 (0.162058) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 90}\n",
      "0.871887 (0.089545) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 100}\n",
      "0.869535 (0.112740) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 110}\n",
      "0.822704 (0.184033) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 120}\n",
      "0.848396 (0.106012) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 130}\n",
      "0.828260 (0.137876) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 140}\n",
      "0.869138 (0.099314) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 150}\n",
      "0.855378 (0.110645) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 160}\n",
      "0.857446 (0.119993) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 170}\n",
      "0.860994 (0.123834) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 180}\n",
      "0.856177 (0.095398) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 190}\n",
      "0.815909 (0.217080) with: {'model__activation_func': 'softplus', 'model__last_layer_nodes': 200}\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=71)\n",
    "grid1 = GridSearchCV(estimator = model1, param_grid= param_grid, n_jobs=-1, scoring = 'r2', cv=kf)\n",
    "grid_result1 = grid1.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "   model__activation_func  model__last_layer_nodes  model__first_layer_nodes  \\\n0                    relu                       10                       200   \n1                    relu                       20                       200   \n2                    relu                       30                       200   \n3                    relu                       40                       200   \n4                    relu                       50                       200   \n5                    relu                       60                       200   \n6                    relu                       70                       200   \n7                    relu                       80                       200   \n8                    relu                       90                       200   \n9                    relu                      100                       200   \n10                   relu                      110                       200   \n11                   relu                      120                       200   \n12                   relu                      130                       200   \n13                   relu                      140                       200   \n14                   relu                      150                       200   \n15                   relu                      160                       200   \n16                   relu                      170                       200   \n17                   relu                      180                       200   \n18                   relu                      190                       200   \n19                   relu                      200                       200   \n20             leaky_relu                       10                       200   \n21             leaky_relu                       20                       200   \n22             leaky_relu                       30                       200   \n23             leaky_relu                       40                       200   \n24             leaky_relu                       50                       200   \n25             leaky_relu                       60                       200   \n26             leaky_relu                       70                       200   \n27             leaky_relu                       80                       200   \n28             leaky_relu                       90                       200   \n29             leaky_relu                      100                       200   \n30             leaky_relu                      110                       200   \n31             leaky_relu                      120                       200   \n32             leaky_relu                      130                       200   \n33             leaky_relu                      140                       200   \n34             leaky_relu                      150                       200   \n35             leaky_relu                      160                       200   \n36             leaky_relu                      170                       200   \n37             leaky_relu                      180                       200   \n38             leaky_relu                      190                       200   \n39             leaky_relu                      200                       200   \n40               softplus                       10                       200   \n41               softplus                       20                       200   \n42               softplus                       30                       200   \n43               softplus                       40                       200   \n44               softplus                       50                       200   \n45               softplus                       60                       200   \n46               softplus                       70                       200   \n47               softplus                       80                       200   \n48               softplus                       90                       200   \n49               softplus                      100                       200   \n50               softplus                      110                       200   \n51               softplus                      120                       200   \n52               softplus                      130                       200   \n53               softplus                      140                       200   \n54               softplus                      150                       200   \n55               softplus                      160                       200   \n56               softplus                      170                       200   \n57               softplus                      180                       200   \n58               softplus                      190                       200   \n59               softplus                      200                       200   \n\n          R2  \n0   0.958613  \n1   0.934811  \n2   0.934409  \n3   0.951170  \n4   0.937980  \n5   0.946756  \n6   0.936221  \n7   0.940796  \n8   0.938116  \n9   0.951490  \n10  0.951634  \n11  0.905791  \n12  0.947242  \n13  0.948373  \n14  0.924367  \n15  0.930649  \n16  0.943442  \n17  0.944401  \n18  0.950589  \n19  0.899466  \n20  0.950312  \n21  0.929584  \n22  0.940615  \n23  0.945347  \n24  0.946011  \n25  0.935047  \n26  0.940793  \n27  0.917589  \n28  0.923078  \n29  0.931042  \n30  0.931176  \n31  0.935937  \n32  0.931898  \n33  0.935238  \n34  0.923627  \n35  0.931929  \n36  0.922444  \n37  0.936763  \n38  0.927567  \n39  0.899530  \n40  0.825313  \n41  0.846319  \n42  0.833903  \n43  0.858258  \n44  0.824389  \n45  0.828122  \n46  0.854196  \n47  0.850090  \n48  0.840874  \n49  0.871887  \n50  0.869535  \n51  0.822704  \n52  0.848396  \n53  0.828260  \n54  0.869138  \n55  0.855378  \n56  0.857446  \n57  0.860994  \n58  0.856177  \n59  0.815909  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model__activation_func</th>\n      <th>model__last_layer_nodes</th>\n      <th>model__first_layer_nodes</th>\n      <th>R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>relu</td>\n      <td>10</td>\n      <td>200</td>\n      <td>0.958613</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>relu</td>\n      <td>20</td>\n      <td>200</td>\n      <td>0.934811</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>relu</td>\n      <td>30</td>\n      <td>200</td>\n      <td>0.934409</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>relu</td>\n      <td>40</td>\n      <td>200</td>\n      <td>0.951170</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>relu</td>\n      <td>50</td>\n      <td>200</td>\n      <td>0.937980</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>relu</td>\n      <td>60</td>\n      <td>200</td>\n      <td>0.946756</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>relu</td>\n      <td>70</td>\n      <td>200</td>\n      <td>0.936221</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>relu</td>\n      <td>80</td>\n      <td>200</td>\n      <td>0.940796</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>relu</td>\n      <td>90</td>\n      <td>200</td>\n      <td>0.938116</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>relu</td>\n      <td>100</td>\n      <td>200</td>\n      <td>0.951490</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>relu</td>\n      <td>110</td>\n      <td>200</td>\n      <td>0.951634</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>relu</td>\n      <td>120</td>\n      <td>200</td>\n      <td>0.905791</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>relu</td>\n      <td>130</td>\n      <td>200</td>\n      <td>0.947242</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>relu</td>\n      <td>140</td>\n      <td>200</td>\n      <td>0.948373</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>relu</td>\n      <td>150</td>\n      <td>200</td>\n      <td>0.924367</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>relu</td>\n      <td>160</td>\n      <td>200</td>\n      <td>0.930649</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>relu</td>\n      <td>170</td>\n      <td>200</td>\n      <td>0.943442</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>relu</td>\n      <td>180</td>\n      <td>200</td>\n      <td>0.944401</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>relu</td>\n      <td>190</td>\n      <td>200</td>\n      <td>0.950589</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>relu</td>\n      <td>200</td>\n      <td>200</td>\n      <td>0.899466</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>leaky_relu</td>\n      <td>10</td>\n      <td>200</td>\n      <td>0.950312</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>leaky_relu</td>\n      <td>20</td>\n      <td>200</td>\n      <td>0.929584</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>leaky_relu</td>\n      <td>30</td>\n      <td>200</td>\n      <td>0.940615</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>leaky_relu</td>\n      <td>40</td>\n      <td>200</td>\n      <td>0.945347</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>leaky_relu</td>\n      <td>50</td>\n      <td>200</td>\n      <td>0.946011</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>leaky_relu</td>\n      <td>60</td>\n      <td>200</td>\n      <td>0.935047</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>leaky_relu</td>\n      <td>70</td>\n      <td>200</td>\n      <td>0.940793</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>leaky_relu</td>\n      <td>80</td>\n      <td>200</td>\n      <td>0.917589</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>leaky_relu</td>\n      <td>90</td>\n      <td>200</td>\n      <td>0.923078</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>leaky_relu</td>\n      <td>100</td>\n      <td>200</td>\n      <td>0.931042</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>leaky_relu</td>\n      <td>110</td>\n      <td>200</td>\n      <td>0.931176</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>leaky_relu</td>\n      <td>120</td>\n      <td>200</td>\n      <td>0.935937</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>leaky_relu</td>\n      <td>130</td>\n      <td>200</td>\n      <td>0.931898</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>leaky_relu</td>\n      <td>140</td>\n      <td>200</td>\n      <td>0.935238</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>leaky_relu</td>\n      <td>150</td>\n      <td>200</td>\n      <td>0.923627</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>leaky_relu</td>\n      <td>160</td>\n      <td>200</td>\n      <td>0.931929</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>leaky_relu</td>\n      <td>170</td>\n      <td>200</td>\n      <td>0.922444</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>leaky_relu</td>\n      <td>180</td>\n      <td>200</td>\n      <td>0.936763</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>leaky_relu</td>\n      <td>190</td>\n      <td>200</td>\n      <td>0.927567</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>leaky_relu</td>\n      <td>200</td>\n      <td>200</td>\n      <td>0.899530</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>softplus</td>\n      <td>10</td>\n      <td>200</td>\n      <td>0.825313</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>softplus</td>\n      <td>20</td>\n      <td>200</td>\n      <td>0.846319</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>softplus</td>\n      <td>30</td>\n      <td>200</td>\n      <td>0.833903</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>softplus</td>\n      <td>40</td>\n      <td>200</td>\n      <td>0.858258</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>softplus</td>\n      <td>50</td>\n      <td>200</td>\n      <td>0.824389</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>softplus</td>\n      <td>60</td>\n      <td>200</td>\n      <td>0.828122</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>softplus</td>\n      <td>70</td>\n      <td>200</td>\n      <td>0.854196</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>softplus</td>\n      <td>80</td>\n      <td>200</td>\n      <td>0.850090</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>softplus</td>\n      <td>90</td>\n      <td>200</td>\n      <td>0.840874</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>softplus</td>\n      <td>100</td>\n      <td>200</td>\n      <td>0.871887</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>softplus</td>\n      <td>110</td>\n      <td>200</td>\n      <td>0.869535</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>softplus</td>\n      <td>120</td>\n      <td>200</td>\n      <td>0.822704</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>softplus</td>\n      <td>130</td>\n      <td>200</td>\n      <td>0.848396</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>softplus</td>\n      <td>140</td>\n      <td>200</td>\n      <td>0.828260</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>softplus</td>\n      <td>150</td>\n      <td>200</td>\n      <td>0.869138</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>softplus</td>\n      <td>160</td>\n      <td>200</td>\n      <td>0.855378</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>softplus</td>\n      <td>170</td>\n      <td>200</td>\n      <td>0.857446</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>softplus</td>\n      <td>180</td>\n      <td>200</td>\n      <td>0.860994</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>softplus</td>\n      <td>190</td>\n      <td>200</td>\n      <td>0.856177</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>softplus</td>\n      <td>200</td>\n      <td>200</td>\n      <td>0.815909</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(params), pd.DataFrame({'model__first_layer_nodes': [200] * len(params)}),pd.DataFrame(means, columns=['R2'])], axis =1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T12:24:28.773492400Z",
     "start_time": "2023-12-25T12:24:28.709988800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merge all files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Pressure_hyperparameter_tuning_3layers\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#Access input folder\n",
    "input_dir = Path (\"Pressure_hyperparameter_tuning_3layers\")\n",
    "print (\"1\",input_dir)\n",
    "\n",
    "# Output Excel file\n",
    "output_excel_file = Path(\"Pressure_hyperparameter_tuning_3layers/S1_summary_3layers.xlsx\")\n",
    "\n",
    "# List to store DataFrames from CSV files\n",
    "dfs = []\n",
    "\n",
    "# Loop through CSV files in the directory\n",
    "for csv_file in input_dir.glob('*.csv'):\n",
    "    # Read CSV file into a DataFrame and append to the list\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate DataFrames in the list along rows\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Write the merged DataFrame to an Excel file\n",
    "merged_df.to_excel(output_excel_file, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T12:26:03.599936900Z",
     "start_time": "2023-12-25T12:26:03.421928700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T12:28:06.611544600Z",
     "start_time": "2023-12-25T12:28:06.579461500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set seed for NumPy\n",
    "np.random.seed(71)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model2():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(units=60, input_shape=(X_train.shape[1],), activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=75, activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=90, activation='relu'))\n",
    " #model.add(Dropout(0.1))\n",
    " model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T12:35:20.996829400Z",
     "start_time": "2023-12-25T12:28:21.517145100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.983931 using {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.709195 (0.165185) with: {'batch_size': 30, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.960317 (0.013291) with: {'batch_size': 30, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.835005 (0.066144) with: {'batch_size': 30, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.711179 (0.162899) with: {'batch_size': 30, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.956524 (0.030609) with: {'batch_size': 30, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.906788 (0.015807) with: {'batch_size': 30, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.546719 (0.296576) with: {'batch_size': 30, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.871970 (0.062510) with: {'batch_size': 30, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.675592 (0.273605) with: {'batch_size': 30, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.879343 (0.048154) with: {'batch_size': 30, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.951835 (0.023377) with: {'batch_size': 30, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.815674 (0.097159) with: {'batch_size': 30, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.875286 (0.056908) with: {'batch_size': 30, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.968512 (0.027970) with: {'batch_size': 30, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.869250 (0.055898) with: {'batch_size': 30, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.840947 (0.051922) with: {'batch_size': 30, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.879461 (0.097173) with: {'batch_size': 30, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.801558 (0.141004) with: {'batch_size': 30, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.911783 (0.052325) with: {'batch_size': 30, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.955671 (0.018510) with: {'batch_size': 30, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.864879 (0.062043) with: {'batch_size': 30, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.904158 (0.063879) with: {'batch_size': 30, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.966077 (0.017568) with: {'batch_size': 30, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.885387 (0.023775) with: {'batch_size': 30, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.880550 (0.085732) with: {'batch_size': 30, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.783002 (0.195559) with: {'batch_size': 30, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.847158 (0.081556) with: {'batch_size': 30, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.937403 (0.032650) with: {'batch_size': 30, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.956225 (0.021010) with: {'batch_size': 30, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.817386 (0.111015) with: {'batch_size': 30, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.923393 (0.057100) with: {'batch_size': 30, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.974189 (0.015269) with: {'batch_size': 30, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.882881 (0.037746) with: {'batch_size': 30, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.922395 (0.047964) with: {'batch_size': 30, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.949044 (0.020866) with: {'batch_size': 30, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.914164 (0.021956) with: {'batch_size': 30, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.965796 (0.007033) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.971631 (0.013331) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.811804 (0.133540) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.956019 (0.022272) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.971317 (0.020469) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.921273 (0.029443) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.957559 (0.011246) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.910959 (0.109973) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.851566 (0.064890) with: {'batch_size': 30, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.592119 (0.284545) with: {'batch_size': 40, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.955884 (0.014371) with: {'batch_size': 40, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.861605 (0.047892) with: {'batch_size': 40, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.596524 (0.280524) with: {'batch_size': 40, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.918091 (0.071592) with: {'batch_size': 40, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.809201 (0.098031) with: {'batch_size': 40, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.445917 (0.358315) with: {'batch_size': 40, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.787764 (0.111194) with: {'batch_size': 40, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.776473 (0.086218) with: {'batch_size': 40, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.842381 (0.047454) with: {'batch_size': 40, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.973289 (0.013389) with: {'batch_size': 40, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.786002 (0.145450) with: {'batch_size': 40, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.843832 (0.049647) with: {'batch_size': 40, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.948776 (0.038381) with: {'batch_size': 40, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.871027 (0.088011) with: {'batch_size': 40, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.788503 (0.075470) with: {'batch_size': 40, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.896898 (0.052020) with: {'batch_size': 40, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.549321 (0.264341) with: {'batch_size': 40, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.891350 (0.054102) with: {'batch_size': 40, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.970511 (0.017326) with: {'batch_size': 40, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.836004 (0.172007) with: {'batch_size': 40, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.888730 (0.060352) with: {'batch_size': 40, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.955888 (0.021847) with: {'batch_size': 40, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.770647 (0.205373) with: {'batch_size': 40, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.839563 (0.115983) with: {'batch_size': 40, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.883350 (0.077964) with: {'batch_size': 40, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.702825 (0.242304) with: {'batch_size': 40, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.910830 (0.067687) with: {'batch_size': 40, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.957357 (0.048822) with: {'batch_size': 40, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.810048 (0.143564) with: {'batch_size': 40, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.919170 (0.052790) with: {'batch_size': 40, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.944106 (0.035899) with: {'batch_size': 40, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.655699 (0.412026) with: {'batch_size': 40, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.897192 (0.072102) with: {'batch_size': 40, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.893642 (0.102756) with: {'batch_size': 40, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.912903 (0.020495) with: {'batch_size': 40, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.939314 (0.037171) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.973152 (0.011490) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.840182 (0.150779) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.948814 (0.022200) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.974766 (0.012404) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.901607 (0.066413) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.923469 (0.049396) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.974667 (0.008579) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.836465 (0.122025) with: {'batch_size': 40, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.566521 (0.296077) with: {'batch_size': 50, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.975322 (0.005780) with: {'batch_size': 50, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.856943 (0.097166) with: {'batch_size': 50, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.569845 (0.297184) with: {'batch_size': 50, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.962222 (0.013079) with: {'batch_size': 50, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.867866 (0.071144) with: {'batch_size': 50, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.359933 (0.442962) with: {'batch_size': 50, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.823297 (0.095585) with: {'batch_size': 50, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.630191 (0.305760) with: {'batch_size': 50, 'epochs': 100, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.832482 (0.071235) with: {'batch_size': 50, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.977011 (0.011651) with: {'batch_size': 50, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.856837 (0.054473) with: {'batch_size': 50, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.832265 (0.071066) with: {'batch_size': 50, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.982973 (0.016156) with: {'batch_size': 50, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.907448 (0.090295) with: {'batch_size': 50, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.765863 (0.100102) with: {'batch_size': 50, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.949604 (0.027779) with: {'batch_size': 50, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.765327 (0.133938) with: {'batch_size': 50, 'epochs': 200, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.883808 (0.066386) with: {'batch_size': 50, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.968510 (0.025627) with: {'batch_size': 50, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.926620 (0.073807) with: {'batch_size': 50, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.880527 (0.071406) with: {'batch_size': 50, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.982185 (0.008519) with: {'batch_size': 50, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.889307 (0.004749) with: {'batch_size': 50, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.848958 (0.094107) with: {'batch_size': 50, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.881966 (0.134796) with: {'batch_size': 50, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.739829 (0.161703) with: {'batch_size': 50, 'epochs': 300, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.908078 (0.059930) with: {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.957365 (0.038204) with: {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.915934 (0.041991) with: {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.908351 (0.061443) with: {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.983931 (0.004661) with: {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.898743 (0.085807) with: {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.893536 (0.064234) with: {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.949077 (0.013896) with: {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.865631 (0.061359) with: {'batch_size': 50, 'epochs': 400, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n",
      "0.935952 (0.039916) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.958611 (0.024966) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.899343 (0.040677) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.934756 (0.041575) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.001}\n",
      "0.983743 (0.008306) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.01}\n",
      "0.941920 (0.036117) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'optimizer__learning_rate': 0.1}\n",
      "0.915037 (0.059364) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.001}\n",
      "0.938817 (0.053865) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.01}\n",
      "0.830217 (0.077054) with: {'batch_size': 50, 'epochs': 500, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>, 'optimizer__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model2 = KerasRegressor(model=create_model2, verbose=0, random_state = 71, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "# define the grid search parameters\n",
    "\n",
    "\n",
    "batch_size = [30,40,50]\n",
    "optimizer = [Adam, Nadam, RMSprop]\n",
    "learning_rate = [ 0.001,0.01, 0.1]\n",
    "epochs = [100, 200, 300, 400, 500]\n",
    "\n",
    "# gridsearch\n",
    "param_grid2 = dict(batch_size=batch_size, optimizer=optimizer, optimizer__learning_rate = learning_rate, epochs = epochs)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=71)\n",
    "grid2 = GridSearchCV(estimator=model2, param_grid=param_grid2, n_jobs=-1, scoring = 'r2', cv=kf)\n",
    "grid_result2 = grid2.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
